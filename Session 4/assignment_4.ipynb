{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_4.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyiHlRMA-Sgg",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries and Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cn_-REV-XEE",
        "colab_type": "code",
        "outputId": "81ce98bb-5125-4b24-ae05-5bf01095c3a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Convolution2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8OU_yF3-idn",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ5LIqV6-de3",
        "colab_type": "code",
        "outputId": "50ee8eb0-21d7-4321-dcde-c078d0059920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PoYHTPn-nZe",
        "colab_type": "code",
        "outputId": "46711821-61b3-4774-931c-86f4e36e16a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8efad420f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi6zjS48-psG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVs65B63-tJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNh7TGlC-vIe",
        "colab_type": "code",
        "outputId": "0642bb69-726f-4385-b371-98d87aa9d5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9-ynNJx-xP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi_lIcfT-zZG",
        "colab_type": "code",
        "outputId": "e1a57b4c-6907-4c54-91c8-2fea44c70d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw07R9QFGZK5",
        "colab_type": "text"
      },
      "source": [
        "### Notes\n",
        "Before we get into the four block codes let's iterate over the 9 steps which were explained during the session to improve the performance of the model gradually.\n",
        "\n",
        "step 1: Started with a vanila network with very basic archtiecture. Kernel of higher dimensions are used which is not used anymore. Validation accuracy of 98.28%, with 68k Parameters in 10 epochs.\n",
        "\n",
        "step 2: Introduced kernels with standard dimension i.e 3x3 or 1x1 and obviously max-pooling was introduced. Only when the output dimension is 7x7, kernel with 7x7 is introduced to make the output dimension match with the number of classes using 10 channels. The kernel channels were in the range of 32, 64, 128. Validation accuracy is 99.18% with 195k parameters in 10 epochs.\n",
        "\n",
        "step 3: The number of channels in each layer was reduced to smaller numbers, which reduced the total number of parameters. Validation accuracy of 98.84%, wtih 10k parametes in 10 epochs.\n",
        "\n",
        "step 4: Batch Normalization was introduced. Validation accuracy of 98.97%, with 11k parametes in 10 epochs and 99.08% accuracy in 30 epochs.\n",
        "\n",
        "step 5: Number of channels in each layer is increased to increase the accuracy on top of the current one. Validation accuracy of 99.05% with 18.4k parameters in 20 epochs.\n",
        "\n",
        "step 6: Dropout is introduced in two places. Validation accuracy is 99.4%, with 18.4k parameters in 21 epochs.\n",
        "\n",
        "step 7: Variable learning rate is introduced where the learning rate changes in every epoch based on the function specified. Validation accuracy of 99.42% with 18.4k paramters in 14 epochs.\n",
        "\n",
        "step 8: Dropout is used after every convolution block(Conv + BN) with 0.1 value. The total number of parameters are also reduced by reducing number of channels in layers. Validation accracy is 99.46% with 16.6k parameters in 11 epochs.\n",
        "\n",
        "step 9: The number of parametes are reduced more and the accuracy is 99.44% with 13k parametes in 15 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phf2VoIF-6nj",
        "colab_type": "text"
      },
      "source": [
        "### First Code Block\n",
        "#### Header Note: Let's first start with vanila network, where we will keep the numbers of channels in such a way that total number of parameters are less than 15k and will follow the standards of making a cnn architecture from scratch. One thing I wanna mention here is, in the  last assignment one mistake I made was I was adding convolution blocks till the image dimension comes down to 1x1. Which is wrong, because at this point the matrix won't have enough information to represent the image. So inplace of that I am gonna use 4x4 convolution in the final layer to get the final classification output, because globalAveragePooling was not introduced till that session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVkTPKUR-1hN",
        "colab_type": "code",
        "outputId": "94b29624-7e18-417b-cb19-3627425099d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(Convolution2D(15, 3, activation='relu')) #24\n",
        "model.add(Convolution2D(20, 3, activation='relu')) #22\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #11\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu')) #9\n",
        "model.add(Convolution2D(15, 3, activation='relu')) #7\n",
        "model.add(Convolution2D(20, 3, activation='relu')) #5\n",
        "\n",
        "model.add(Convolution2D(10, 5, activation='relu')) #1\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0905 16:28:19.326583 139725091018624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0905 16:28:19.373362 139725091018624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0905 16:28:19.381644 139725091018624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0905 16:28:19.454867 139725091018624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 15)        1365      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 20)        2720      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 22, 22, 10)        210       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 15)          1365      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 20)          2720      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          5010      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,400\n",
            "Trainable params: 14,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu_2HnG67XEC",
        "colab_type": "code",
        "outputId": "9663f3d2-59c0-422d-ca7e-15d7da68f1a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0905 16:28:19.574779 139725091018624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0905 16:28:19.621370 139725091018624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brZjyoz27XGj",
        "colab_type": "code",
        "outputId": "67c47837-9324-47a3-bee7-60609a1c0b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "W0905 16:28:21.258214 139725091018624 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0905 16:28:21.353267 139725091018624 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 28s 464us/step - loss: 1.0881 - acc: 0.5760\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.7818 - acc: 0.6779\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.7637 - acc: 0.6808\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 22s 366us/step - loss: 0.7548 - acc: 0.6823\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.7514 - acc: 0.6829\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.7466 - acc: 0.6841\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.7432 - acc: 0.6846\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 21s 356us/step - loss: 0.7392 - acc: 0.6851\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.7375 - acc: 0.6857\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 21s 357us/step - loss: 0.7370 - acc: 0.6855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f13ee05c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6xgDFaDKSWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvLNt-BkKTYx",
        "colab_type": "code",
        "outputId": "13faf4fe-ae56-41fc-98a3-5e603e65956d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7434452826976776, 0.6836]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK-ulAkMDP2v",
        "colab_type": "text"
      },
      "source": [
        "### Second Code Block\n",
        "#### Header Note: Now that we have the basic struture of the network and the total number of parameters are 14400. Let's introduce Batch Normalization and Dropout to each of the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twnsLP0d7XJM",
        "colab_type": "code",
        "outputId": "bf11432d-488e-4eee-c360-af3a4522caaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(15, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(20, 3, activation='relu')) #22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #11\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu')) #9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(15, 3, activation='relu')) #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(20, 3, activation='relu')) #5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 5, activation='relu')) #1\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 24, 24, 15)        1365      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 15)        60        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 24, 24, 15)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 20)        2720      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 22, 22, 20)        80        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 22, 22, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 22, 22, 10)        210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 22, 22, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 22, 22, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 9, 9, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 7, 7, 15)          1365      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 15)          60        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 7, 7, 15)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 5, 5, 20)          2720      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 5, 5, 20)          80        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 5, 5, 20)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 1, 10)          5010      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,800\n",
            "Trainable params: 14,600\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOyXWeld7XLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCJhJqSJ7XOH",
        "colab_type": "code",
        "outputId": "ca239b2a-94b8-454e-859f-8fe9bfdd39bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 41s 688us/step - loss: 0.2512 - acc: 0.9200\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 40s 660us/step - loss: 0.0740 - acc: 0.9771\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 40s 663us/step - loss: 0.0577 - acc: 0.9818\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 39s 658us/step - loss: 0.0502 - acc: 0.9841\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 39s 653us/step - loss: 0.0454 - acc: 0.9855\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 39s 656us/step - loss: 0.0414 - acc: 0.9870\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 39s 653us/step - loss: 0.0370 - acc: 0.9885\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 39s 651us/step - loss: 0.0346 - acc: 0.9890\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 39s 654us/step - loss: 0.0331 - acc: 0.9897\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 39s 651us/step - loss: 0.0320 - acc: 0.9899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f13ea871e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L589KeVF7XQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S5T9NI3JxUH",
        "colab_type": "code",
        "outputId": "53891e1d-b9cb-4cb7-98cd-c41b0de152b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.028191434921199108, 0.9911]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZzjpa1BJ6Wk",
        "colab_type": "text"
      },
      "source": [
        "### Third Code Block\n",
        "#### Header Note: Because of the introduction of Batch Normalisation and Dropout the accuracy increased from 68.36% to 99.11%. In this block the variable learning rate will be introduced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D0jZnYrJxWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9de36de-be65-4b71-afc8-5a6eda47ed39"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(15, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(20, 3, activation='relu')) #22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #11\n",
        "\n",
        "model.add(Convolution2D(10, 3, activation='relu')) #9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(15, 3, activation='relu')) #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(20, 3, activation='relu')) #5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 5, activation='relu')) #1\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 15)        1365      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 24, 24, 15)        60        \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 24, 24, 15)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 22, 22, 20)        2720      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 22, 22, 20)        80        \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 22, 22, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 22, 22, 10)        210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 22, 22, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 22, 22, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 9, 9, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 7, 7, 15)          1365      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 7, 7, 15)          60        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 7, 7, 15)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 5, 5, 20)          2720      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 5, 5, 20)          80        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 5, 5, 20)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1, 1, 10)          5010      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,800\n",
            "Trainable params: 14,600\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7I2JZhtJxZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVySYEZ_Jxb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXKYbaiXJxeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3682697a-3bd3-49da-807a-83b244956551"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 40s 669us/step - loss: 0.0467 - acc: 0.9855 - val_loss: 0.0313 - val_acc: 0.9897\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 40s 671us/step - loss: 0.0316 - acc: 0.9901 - val_loss: 0.0291 - val_acc: 0.9918\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 40s 665us/step - loss: 0.0281 - acc: 0.9909 - val_loss: 0.0233 - val_acc: 0.9926\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 40s 665us/step - loss: 0.0246 - acc: 0.9922 - val_loss: 0.0226 - val_acc: 0.9927\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 40s 666us/step - loss: 0.0221 - acc: 0.9933 - val_loss: 0.0210 - val_acc: 0.9937\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 40s 669us/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0237 - val_acc: 0.9924\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 40s 666us/step - loss: 0.0195 - acc: 0.9940 - val_loss: 0.0219 - val_acc: 0.9932\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 40s 666us/step - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0231 - val_acc: 0.9927\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 40s 670us/step - loss: 0.0164 - acc: 0.9943 - val_loss: 0.0235 - val_acc: 0.9925\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 40s 674us/step - loss: 0.0156 - acc: 0.9948 - val_loss: 0.0211 - val_acc: 0.9938\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 40s 667us/step - loss: 0.0136 - acc: 0.9954 - val_loss: 0.0197 - val_acc: 0.9939\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 40s 668us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0200 - val_acc: 0.9939\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 40s 667us/step - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0205 - val_acc: 0.9934\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 40s 672us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0216 - val_acc: 0.9937\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 40s 668us/step - loss: 0.0122 - acc: 0.9957 - val_loss: 0.0207 - val_acc: 0.9939\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 40s 669us/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0198 - val_acc: 0.9943\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 41s 677us/step - loss: 0.0133 - acc: 0.9959 - val_loss: 0.0198 - val_acc: 0.9939\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 40s 670us/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0217 - val_acc: 0.9935\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 40s 668us/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0199 - val_acc: 0.9942\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 40s 668us/step - loss: 0.0124 - acc: 0.9959 - val_loss: 0.0188 - val_acc: 0.9940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ea8219668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaveBerFCGcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjSw_adTESPp",
        "colab_type": "code",
        "outputId": "b313561b-c55b-4924-cee7-02b8a92333cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01880754358768354, 0.994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvOsblUNEVEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}