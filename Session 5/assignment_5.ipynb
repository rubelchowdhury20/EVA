{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt5FK3-ok7yi",
        "colab_type": "code",
        "outputId": "2c0ec39c-2c1a-4b84-a1d8-d8ff9c476dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYj_7pqdsz2U",
        "colab_type": "code",
        "outputId": "393043ef-cc61-4a8b-8c0a-821dafaa900c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlYl6y9AuSDh",
        "colab_type": "code",
        "outputId": "84aa5bfd-b58a-434f-ac26-c80d448db478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fab0aeaaf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta863EuvuUYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRGIppuKuXw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efxm5BaBuaug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-YtOV_9udcX",
        "colab_type": "code",
        "outputId": "b87aa75a-ac3d-484f-b8c1-a538e29459b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cftHhK40ugBv",
        "colab_type": "code",
        "outputId": "45740026-a966-469e-d775-4b473f4a7a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otJLSuPOpyF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liz_34PDuial",
        "colab_type": "code",
        "outputId": "8fe6a1f1-b4c3-4ad9-84c9-173f77ef3b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 16s 270us/step - loss: 0.5219 - acc: 0.8551 - val_loss: 0.0934 - val_acc: 0.9807\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.2470 - acc: 0.9277 - val_loss: 0.0564 - val_acc: 0.9879\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1938 - acc: 0.9434 - val_loss: 0.0433 - val_acc: 0.9905\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1644 - acc: 0.9482 - val_loss: 0.0417 - val_acc: 0.9906\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1500 - acc: 0.9493 - val_loss: 0.0440 - val_acc: 0.9887\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.1371 - acc: 0.9526 - val_loss: 0.0304 - val_acc: 0.9920\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1286 - acc: 0.9533 - val_loss: 0.0283 - val_acc: 0.9916\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.1204 - acc: 0.9536 - val_loss: 0.0281 - val_acc: 0.9922\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.1146 - acc: 0.9551 - val_loss: 0.0215 - val_acc: 0.9938\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.1093 - acc: 0.9547 - val_loss: 0.0219 - val_acc: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2fec1b4a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUiWhNRMulz4",
        "colab_type": "code",
        "outputId": "3ed644cf-ff95-441f-bdd9-54386660a9f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0218935436445754, 0.9931]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ6amyJSr-RT",
        "colab_type": "text"
      },
      "source": [
        "Whatever we have seen above was the basic code from previous assignment.\n",
        "Now we have to add Image Normalization. But before that let's first check the mean value and standard deviation of train and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLwynCiAsHoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing ImageDataGenerator class so that we can add image normalization to \n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhWlHMifw7pf",
        "colab_type": "code",
        "outputId": "061e25ec-9eca-4f10-df03-c83266a8e629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Mean value of train dataset is {}\".format(X_train.mean()))\n",
        "print(\"Standard Deviation of train dataset is {}\".format(X_train.std()))\n",
        "print(\"Mean value of test dataset is {}\".format(X_test.mean()))\n",
        "print(\"Standard Deviation of test dataset is {}\".format(X_test.std()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean value of train dataset is 0.13066062331199646\n",
            "Standard Deviation of train dataset is 0.30810776352882385\n",
            "Mean value of test dataset is 0.13251467049121857\n",
            "Standard Deviation of test dataset is 0.3104802668094635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4io3MY84Y7u",
        "colab_type": "text"
      },
      "source": [
        "#### Now we will add image normalization to the train and test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIKm9aU1xmL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create generator that centers pixel values i.e image normalization\n",
        "train_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "test_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdmYGzTBzGsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fitting the train and test data with the specified normalization normalization\n",
        "train_datagen.fit(X_train)\n",
        "test_datagen.fit(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un0h0GMszWKi",
        "colab_type": "code",
        "outputId": "aab2bacc-064e-4f9f-ca1c-ad690beb744c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl4H5mTiDuWM",
        "colab_type": "code",
        "outputId": "72c092e0-ae34-4581-b5f0-4469f223cb72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_datagen.flow(X_train, Y_train, batch_size=128), epochs=10, verbose=1, validation_data=test_datagen.flow(X_test, Y_test, batch_size=128), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.5333 - acc: 0.8533 - val_loss: 0.0938 - val_acc: 0.9805\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.2501 - acc: 0.9264 - val_loss: 0.0655 - val_acc: 0.9875\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.2006 - acc: 0.9400 - val_loss: 0.0495 - val_acc: 0.9893\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/469 [==============================] - 13s 29ms/step - loss: 0.1699 - acc: 0.9462 - val_loss: 0.0408 - val_acc: 0.9898\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1492 - acc: 0.9500 - val_loss: 0.0381 - val_acc: 0.9890\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1373 - acc: 0.9520 - val_loss: 0.0283 - val_acc: 0.9914\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1274 - acc: 0.9537 - val_loss: 0.0308 - val_acc: 0.9913\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1218 - acc: 0.9544 - val_loss: 0.0265 - val_acc: 0.9927\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1164 - acc: 0.9548 - val_loss: 0.0257 - val_acc: 0.9926\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1130 - acc: 0.9550 - val_loss: 0.0258 - val_acc: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2feb3bb0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5gs6Q06EmE0",
        "colab_type": "code",
        "outputId": "4787b7cd-e6a9-43e4-ca0d-55ae45096928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(test_datagen.flow(X_test, Y_test, batch_size=128), verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.025816280198656023, 0.9931]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNHe3qNe_HSo",
        "colab_type": "text"
      },
      "source": [
        "#### After image normalization the next step is to add l2 regularization. So applying L2 regularization to all the cnn layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOPfAsbcmi0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing keras regularizier\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF9zIhxjFw0L",
        "colab_type": "code",
        "outputId": "b1bc8167-95ec-4331-e74b-180d3ec69076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Defining the model architecture again along with l2 regularization\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', kernel_regularizer=l2(0.0005), input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', kernel_regularizer=l2(0.0005))) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', kernel_regularizer=l2(0.0005))) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', kernel_regularizer=l2(0.0005)))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', kernel_regularizer=l2(0.0005)))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', kernel_regularizer=l2(0.0005)))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', kernel_regularizer=l2(0.0005)))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4, kernel_regularizer=l2(0.0005)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg..., input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4), kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzrG15-Rmh9c",
        "colab_type": "code",
        "outputId": "37f31680-c94e-4d76-fc82-3da8ceef41ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_datagen.flow(X_train, Y_train, batch_size=128), epochs=10, verbose=1, validation_data=test_datagen.flow(X_test, Y_test, batch_size=128), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 0.5558 - acc: 0.8606 - val_loss: 0.2195 - val_acc: 0.9686\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.2950 - acc: 0.9274 - val_loss: 0.1119 - val_acc: 0.9878\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/469 [==============================] - 14s 29ms/step - loss: 0.2337 - acc: 0.9419 - val_loss: 0.1031 - val_acc: 0.9857\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.2056 - acc: 0.9457 - val_loss: 0.0735 - val_acc: 0.9905\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1851 - acc: 0.9486 - val_loss: 0.0644 - val_acc: 0.9912\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1720 - acc: 0.9501 - val_loss: 0.0624 - val_acc: 0.9909\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/469 [==============================] - 13s 29ms/step - loss: 0.1597 - acc: 0.9518 - val_loss: 0.0545 - val_acc: 0.9933\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1500 - acc: 0.9537 - val_loss: 0.0533 - val_acc: 0.9931\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/469 [==============================] - 13s 29ms/step - loss: 0.1434 - acc: 0.9534 - val_loss: 0.0482 - val_acc: 0.9935\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/469 [==============================] - 13s 29ms/step - loss: 0.1389 - acc: 0.9537 - val_loss: 0.0537 - val_acc: 0.9914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faabc2264a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgqFBwNGpnoH",
        "colab_type": "code",
        "outputId": "c6eef167-18d3-45bc-a40e-34c7db72d56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(test_datagen.flow(X_test, Y_test, batch_size=128), verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.053661593168973926, 0.9914]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLE42lBQdM9D",
        "colab_type": "text"
      },
      "source": [
        "#### Now the next step is to add activation layer after batch normlization and running for 40 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CB4-M4edLK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation # activation to be used as a layer\n",
        "from keras.callbacks import ModelCheckpoint # Library to be used for saving the best checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq5MeYTiVHCD",
        "colab_type": "code",
        "outputId": "54b2fdb3-3dce-4753-bf5b-bef8faddf54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Defining the model architecture again along with l2 regularization\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.0005), input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, kernel_regularizer=l2(0.0005))) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', kernel_regularizer=l2(0.0005))) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.0005)))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.0005)))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.0005)))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.0005)))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4, kernel_regularizer=l2(0.0005)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4), kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYnhiSQr0hgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint for saving the model with highest validation accuracy\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYc6xxSfmU1M",
        "colab_type": "code",
        "outputId": "333ea0df-5958-4117-bbc8-b995119d300c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_datagen.flow(X_train, Y_train, batch_size=128), epochs=40, verbose=1, validation_data=test_datagen.flow(X_test, Y_test, batch_size=128), callbacks=[LearningRateScheduler(scheduler, verbose=1), checkpoint])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.5857 - acc: 0.8500 - val_loss: 0.3449 - val_acc: 0.9317\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.93170, saving model to weights-improvement-01-0.93.hdf5\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.2943 - acc: 0.9263 - val_loss: 0.1416 - val_acc: 0.9810\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.93170 to 0.98100, saving model to weights-improvement-02-0.98.hdf5\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.2422 - acc: 0.9376 - val_loss: 0.0863 - val_acc: 0.9885\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98100 to 0.98850, saving model to weights-improvement-03-0.99.hdf5\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.2093 - acc: 0.9448 - val_loss: 0.0996 - val_acc: 0.9825\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.98850\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1877 - acc: 0.9485 - val_loss: 0.0684 - val_acc: 0.9914\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.98850 to 0.99140, saving model to weights-improvement-05-0.99.hdf5\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/469 [==============================] - 13s 29ms/step - loss: 0.1730 - acc: 0.9493 - val_loss: 0.0629 - val_acc: 0.9908\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.99140\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1605 - acc: 0.9529 - val_loss: 0.0569 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.99140 to 0.99150, saving model to weights-improvement-07-0.99.hdf5\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1525 - acc: 0.9522 - val_loss: 0.0566 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.99150 to 0.99180, saving model to weights-improvement-08-0.99.hdf5\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1504 - acc: 0.9513 - val_loss: 0.0627 - val_acc: 0.9895\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.99180\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1430 - acc: 0.9529 - val_loss: 0.0540 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99180\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1370 - acc: 0.9541 - val_loss: 0.0604 - val_acc: 0.9893\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99180\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1360 - acc: 0.9530 - val_loss: 0.0468 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.99180 to 0.99260, saving model to weights-improvement-12-0.99.hdf5\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1302 - acc: 0.9552 - val_loss: 0.0440 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99260\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1272 - acc: 0.9559 - val_loss: 0.0435 - val_acc: 0.9931\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.99260 to 0.99310, saving model to weights-improvement-14-0.99.hdf5\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "469/469 [==============================] - 13s 29ms/step - loss: 0.1231 - acc: 0.9565 - val_loss: 0.0423 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.99310 to 0.99370, saving model to weights-improvement-15-0.99.hdf5\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1224 - acc: 0.9565 - val_loss: 0.0407 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99370\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1223 - acc: 0.9562 - val_loss: 0.0461 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99370\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1179 - acc: 0.9565 - val_loss: 0.0412 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99370\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.1183 - acc: 0.9552 - val_loss: 0.0386 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.99370 to 0.99390, saving model to weights-improvement-19-0.99.hdf5\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1121 - acc: 0.9570 - val_loss: 0.0381 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.99390 to 0.99420, saving model to weights-improvement-20-0.99.hdf5\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1131 - acc: 0.9560 - val_loss: 0.0368 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99420\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1104 - acc: 0.9569 - val_loss: 0.0342 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.99420 to 0.99430, saving model to weights-improvement-22-0.99.hdf5\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1125 - acc: 0.9571 - val_loss: 0.0391 - val_acc: 0.9930\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99430\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1079 - acc: 0.9585 - val_loss: 0.0379 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99430\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1084 - acc: 0.9577 - val_loss: 0.0364 - val_acc: 0.9935\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99430\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1058 - acc: 0.9577 - val_loss: 0.0340 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99430\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.1090 - acc: 0.9568 - val_loss: 0.0341 - val_acc: 0.9937\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99430\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1061 - acc: 0.9583 - val_loss: 0.0355 - val_acc: 0.9942\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99430\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1061 - acc: 0.9580 - val_loss: 0.0347 - val_acc: 0.9939\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99430\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1018 - acc: 0.9599 - val_loss: 0.0338 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.99430 to 0.99450, saving model to weights-improvement-30-0.99.hdf5\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1036 - acc: 0.9588 - val_loss: 0.0325 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.99450\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1044 - acc: 0.9567 - val_loss: 0.0344 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.99450\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1023 - acc: 0.9577 - val_loss: 0.0336 - val_acc: 0.9953\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.99450 to 0.99530, saving model to weights-improvement-33-1.00.hdf5\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0986 - acc: 0.9610 - val_loss: 0.0336 - val_acc: 0.9948\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99530\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.1007 - acc: 0.9584 - val_loss: 0.0340 - val_acc: 0.9950\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99530\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0990 - acc: 0.9594 - val_loss: 0.0321 - val_acc: 0.9949\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.99530\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0981 - acc: 0.9598 - val_loss: 0.0312 - val_acc: 0.9943\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.99530\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.0991 - acc: 0.9589 - val_loss: 0.0288 - val_acc: 0.9951\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.99530\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.0980 - acc: 0.9582 - val_loss: 0.0320 - val_acc: 0.9947\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.99530\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "469/469 [==============================] - 14s 31ms/step - loss: 0.0984 - acc: 0.9597 - val_loss: 0.0315 - val_acc: 0.9945\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.99530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faaba205e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkE_H5-qtlxx",
        "colab_type": "code",
        "outputId": "6e162730-da1f-40ac-8327-628a14ab7b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ascore = model.evaluate(test_datagen.flow(X_test, Y_test, batch_size=128), verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.030682271525263788, 0.995]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OowhL9HDs5H",
        "colab_type": "text"
      },
      "source": [
        "#### Code to find the misclassified images and visualization of them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozZ-wBrxwYSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the prediction on test data\n",
        "prediction = model.predict(test_datagen.flow(X_test, shuffle=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvx8zLvATujD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the class from the prediction\n",
        "prediction = np.argmax(prediction, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8YKcM8IQDro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the class from the test set like the prediction\n",
        "Y_test = np.argmax(Y_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Su0uhaTgCp",
        "colab_type": "code",
        "outputId": "a56f2808-8007-40fa-9539-196f775a52c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWKrU5iLTgH3",
        "colab_type": "code",
        "outputId": "77291de2-1e18-40a5-c523-f97252900d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6XHoEfCSQhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding the cases for which the prediction is wrong from the ground truth\n",
        "wrong_indices = [i for i in range(len(prediction)) if prediction[i] != Y_test[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QLLkhCVShmR",
        "colab_type": "code",
        "outputId": "b687e8dd-3a40-4606-e9a8-b71976cabe9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# total number of instances for which the prediction was wrong\n",
        "len(wrong_indices)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "temLhuNIMVEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6TOYV8dL6Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_to_plot = 25\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR_w7blCN85O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b49ccf1f-2302-464d-8c63-79188c6f72ee"
      },
      "source": [
        "plt.clf()\n",
        "plt.style.use('seaborn-muted')\n",
        "\n",
        "fig, axes = plt.subplots(5,5, \n",
        "  figsize=(15, 15),\n",
        "  sharex=True, sharey=True,\n",
        "  subplot_kw=dict(adjustable='box-forced', aspect='equal'))\n",
        "\n",
        "for i in range(images_to_plot):\n",
        "    \n",
        "    # axes (subplot) objects are stored in 2d array, accessed with axes[row,col]\n",
        "    subplot_row = i//5\n",
        "    subplot_col = i%5 \n",
        "    ax = axes[subplot_row, subplot_col]\n",
        "\n",
        "    # plot image on subplot\n",
        "    plottable_image = X_test[wrong_indices[i]].squeeze()\n",
        "    ax.imshow(plottable_image, cmap='gray_r')\n",
        "    \n",
        "    ax.set_title('Ground Truth: {}, Prediction: {}'.format(Y_test[wrong_indices[i]], prediction[wrong_indices[i]]))\n",
        "    ax.set_xbound([0,28])\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:1334: MatplotlibDeprecationWarning: \n",
            "box-forced\n",
            "  \"2.2\", \"box-forced\", obj_type=\"keyword argument\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCYAAAQjCAYAAAC8Zi+MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xu8XOPZ//HvRUIkUWnkpBUJDZo4\nRUXKg+CHoo5BSYOm7eNJSwkaVJOoOEVKPQ59FCnifCiRUqXiUGciUaTSlBA5kcMOIgeRkFy/P+61\nmezeK3tm9pq99uHzfr3yyp7vrFnrnjXrmjVzz1rrNncXAAAAAABAHtbLuwEAAAAAAKD5omMCAAAA\nAADkho4JAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuaFjAgAAAAAA5KZZd0yY2Uwz2z/H5c81s33y\nWn6lmNnFZnZL8vdWZraszPmcZ2bXZ9o4VBx1VRlmdpKZPZ38vb6ZLTOzLcqYzyAzezTzBqKiqKvK\noK6aN+qqMqir5ouaqozmUlMV7ZgwswFmNtHMlpvZwuTvU8zMKrncujKzR5MXfJmZfW5mqwpul/VF\n2czuMLORGTe1et63mZmbWfcip9/fzNYkz2epmf3bzAZVom3uPsPd2xbZppk1HnuRu/+8Eu2qsWwz\ns9+Y2WwzW2Jmd5lZrW3OC3W11jwzrau6bAtm1iOpw+rn9J6ZnZ1V2wq5+2p3b+vus4tpU43H3uru\nB1eiXZHl/zB5f1lqZm+a2WH1sdxyUFdrzTPrujrczF40s8VmNs/MbqCuypN8qFxW8O/TZP3sVOll\nl4O6WmuemX8ONLNOZna3mX1iZh+b2W1FPo66+s/lf8/M3kpq6ikr40tffaCm1ppn1vuq/ZPPKovN\nbJGZjTOzzYp8LDUVWXaN/dWw2h5XsY4JMxsq6WpJl0vqIqmzpJ9L2kPSBimPWb9S7SmFux+cvOBt\nJd0p6bLq27EvymbWov5b+eWy95HUvYyHzk6e39ckDZd0k5ltG5l/bs+tHv1U0gBJu0v6psI6uTrX\nFqWgriquzttCwXM8UdKFFvnloDnUVfKh7lZJQxTW4zBJ95rZprk2LIK6qriNJV0gaTNJ20naUtLo\nUmZAXQXJh8q2BetjiKS33f2NvNtWE3VVLx6UNEdSV0mdJF1ZyoOpq8DMOku6X9KvJW0q6XVJd+Xa\nqAhqquLelHSAu7dT+Aw4U9K1pcyAmlpb4f7K3UcV84DM/0naRNJySUfXMt0tkq6T9Egy/f7JY2+T\nVCVplqQRktZLph8p6Y6Cx3eX5JJaJLeflnSRpBckLZU0QVKHgulPTOb5ocKX8ZmS9i+ijRfXyPZP\nHjtM0nxJYyWdJOnpgmlaJG3rLukUSZ9LWiVpmaTxyTRzJf1S0j8lfSLpbkkblrCeW0p6Q9JO1csq\n8nH7S5pZI/tY0pGSeiTz+omk2ZKeSu7fQ9LLkhYrvGH3K3jsVpKeS9b5Y8lrektyX4+wmX057abJ\nOp2XLHNc8pqvkLQmWT/LFHawF1fPJ3lsf0lTkzY8JWnbgvvKXpeS/izpzILb/SR9KqlVJeqDumq4\ndVWXbaHmtp5kr0k6o6Ddp0h6R9I7yf29JD0h6SNJ/y58bSV1lPSwpCUKtXdJ9booXA/J7dYKH0hn\nJ8/5WUkbSvogma66rnaNrNM9JU1OHveKpO8W3Pe8whfKF5PX/m+S2he5LveQ9EHkfWbXvGuJuqr/\n/VWNNh0r6bUip6Wu1r1+npM0PO86oq5y2V99X9K71eumxNeHulr7uZ8i6dmC21+TtFJSj7xriZrK\nZ18lqZVCB9AUaqqsmvqP9VHMv0odMbF7skIeLGLagQore2OFFfB7hQLaStLekn6k8CW5WAOT6Tsp\n9B6eJUlm1kuhUE+U9A2FL8iblzDfmjaX1FbSFgobWip3/4OkeyWN8tBj1L/g7mMlHaDwfHdJ2ld9\n/tBiM9ttHbM+S2GDnlrukzCz9czsmOS5/LPgrn6Svi3pEDPrKukhSedLai/pXEkPFPzyea9C0XSQ\ndGn1c0hxl8Lr0kvhNbra3T+RdJiSoziSfwtrtLOnpNslnaZQrE9IesjMWhZMVpd1aTX+3kjSt9Yx\nfR6oqwIVrKs6bwsW7CWpp8KOqdrhCjuGHSwcyv64woeFTpKOlzSm4Mil6xR2BF0kDVY4miPNlZJ2\nlPRdhRodptDR109aq8d6Uo12dpD0V0lXKLx2v5f0iJl9vWCygZIGKfwy00Zhh1/9+KlmdmxKmyZK\netfMDknW+9HJ83lzHc8jD9RVgQrWVaF+KmO/RV39x/r4lqT/Utg3NjTUVYEK1dVukt6SdIeZfWhm\nr5jZnqU+CepKUjiS68ujjtx9iaT3kryhoKYKVGpfZWZbmtlihR+lTpd0WalPgppaaxlzzWyOmd1c\nzBGzleqY6CBpkbt/UdCw6vNLV5hZv4JpH3T3F9x9jULP1wBJv3b3pe4+U2FlreuLbk1j3f1td18h\n6U+Seif5MZIedvdn3X2lpPMUXrRyfSFppLuvSpZVrqvcfb67f6jQM9Zb+vL8oXbu/nLsQWbWTWEj\nHVnmcrdICm+RQg/n8e7+bsH957v7p8lz+5Gkh9z9MXdf4+5/U3gDP8jMtlI4YuN8d1/p7k8r9NLG\n2txV0n6STnb3j939c3d/tsj2Dkja8JS7f65wGPAmCkVYrax1qdADONjMuplZO0nnJHnrIttWX6ir\n4uW2LSR19ZGkMZKGuvszBXePSrb9FZKOUDgE+zZ3/8LdX1U4YuOYpMPtSEnnJXU4RSlfPpLDNH8s\naYi7z0ue4/NJndTmMElT3f3upA23S5oh6ZCCaW5y9+nu/qmk+/TVay93387d/xSbcbKd3qawvaxM\n/h5cx9e1Eqir4pVbV18ys4MVPuicX8qCqauoH0n6u9dynnFOqKvilVtXm0s6WOFI1S4Kh/g/ZGbt\ni10wdfWltgq/GBf6ROGLfUNBTRWv7H2Vu7/n4VSOjpJ+o9D5VzRq6ksLJfWR1E1SX0lfV/gcuE6V\nOsflQ0kdzKxFdQG5+39JoedEa3eIzCn4u4PC6QmzCrJZCuf5FGt+wd+fKrzZSKEn78tluftyM/uw\nhPnWtMDdV9Xh8dVqtrfYHco1Cp0BS628c5Vmu3v3ddxf+Lp0k/RDMyvsjWyp8CXuG5I+TDbYarMU\nCrqmrgpvqjXf/IvxDRVsF+6+JtmWCreNctflHxV28M8qbJtXKhwiObeMdlYSdVW83LaFZIeWpmZd\n7ZHsxKq1UDjEsbOk9WtMP0vhzb2mzgq/YLwbua82a9VVwXLWVVfFXrTwIEmjJO2lcPrXrpIeNLMD\n3P2f63xw/aKuilduXUmSzOy/FD6YHOVrd4TXirpam5mZQsfEb8poX32gropXbl2tUDgk/Nbk9p1m\nNkLhl/W/FjMD6upLyxRO3yj0NYVfrBsKaqp4ddpXSZK7f2hmd0iaZGbfTDp5inkcNaUvjzp6Nbk5\nz8xOkzTbzFrX+M64lkodMfGSwi9kRxQxrRf8vUihZ69bQbaFpPeTv5dr7V8uu5TQpnkKX4wlSWbW\nWuGwlXJ5jdu1ta3m9HW1n6T/NbP5+upL0yQzOy6Lmbt7YXvnKPSWtiv418bdL1dYr5ua2UYF06dd\nyXiOwptqzTd/qfb184EKtgszW0/hC+T7qY8oUtK7OMLdu7l7V4XzvOZo7WJsCKirCtdVPWwLNevq\nyRp11dbdT5W0QOFXh64F06fV1QKFcyxjp5uUVFcFy6lzXSn0qj/t7v/wcKTVRIXzGPfLYN5Zoq4q\nv7+SmfVR+DVokIcj67LUnOqqWj+FLxwPZDjPLFFXla+rKZF5ZrmM5lRXUxWO/pUkmdnGChfpLftU\n6QqgpuphX1VDi2SZWY3U15xqKq0t6xw9piIdE+6+WOFiGX8ws2PMbGML1zLorXB+StrjViscInRJ\n8phuCuey3JFM8rqkfma2hZltonD13GLdL+lQM9vTzDaQdKGyff5vSNrRzHZIvqTXPEx1gcK5TlnZ\nSuGDf2+F86ek8MvuQ9KXQ+jcmNGybpfU38wOSM7PamVm+5rZN5JfvaZIGmlmGySHkh0Sm4m7z1G4\nNsS1ZtbOzFoWHHq2QKHTIu2wuT9JOtzM9kkOcTpboSd7Yl2fnJl1MLOtLNhe0u8UDiWr9BteSair\nytdVbduCmV1sZk9ktLiHJG1nZgOTWmhpZn3NbNvkELw/S7rAzDZK2hI97DJ5fW+RdJWZdUlqdI+k\nThZKcgunXMU8nLThODNrYWYDFS5YVNSvbbWYJGlvM9tR+vKL6R4K7xcNBnVVL3W1k8Ipfqe4+3+c\n6kddlWWQpPvcfXmG88wMdVUvnwPHSepsZscn2+dxCueqvyRRVyUaJ6m3mR1pZq0UXrvJ7v5OBvPO\nBDVVL/uqo81s6+QzYCeFU14mJb/+U1MlMLPdzGybZBvtqHCq2ZO17bMqNlyou1+msOGfo7DhLJB0\ng6RfKVzdM81pCj1kMxQu2HKXpJuTeT6ucKGTKQqHhzxcQnumSvpFMr/qESEyO1Tf3f+lcNjy0wrn\nI9W8dsKNknayMM70/bXNL9mwlpnZ7inLW+jh/Kn5CutWkqr8q3OyuipcQbfOPJyP1l/h3LEqhau+\nDtVX288AhS8cHylcr2JdF+I6Ifn/7aTdpyXLeFNhxzDTwvlynWq0YarCB7HrkjYcJOnwYs6hqm1d\nKpx28jeF7e5hSTe4+821zTcP1FVl60q1bwtZ1tUnkg5UqIl5CkdlXKpwcStJOlnhnLwFkm5SuEJ1\nmjMlTVN4/T5SWGfm7kuTeU5M6qpPjTZUKVyM6VcKh4meKelQd/+4mOdgYcz36FFa7v6kwsg6481s\nqcI2doG7P1XMvOsTdVXxujpLyYhM9tV45oXDW1JXBdZVV8n9rRXO7b41bZqGgLqq+OfARQq/nv9a\n4XoIZyl8LvoomYS6KlDL/mqBwgUTL1PYLr6jcC2cBoWaqvi+qqvCqCPLFDpFVim81xbeT00latlX\n9VBYl0sV1uUyhQt8rnueDexHYWQg6e39h6QdveAiOQDqxsymSNq72DdtALWjroDsUVdAtqipyqNj\nAgAAAAAA5KZip3IAAAAAAADUho4JAAAAAACQGzomAAAAAABAblrU5cFmdpDC8B/rS7rR3Ueva/oO\nHTp49+7d67JIoGJeffXVRe7eMe92lIq6QkPWGOuKmkJD1hhrSqKu0LBRV0D2Sq2rsjsmzGx9SddK\nOkBhaJhJZvZQMrRLVPfu3TV58uRyFwlUlJnNyrsN5aCu0JA1xrqiptCQNcaakqgrNGzUFZC9Uuuq\nLqdy9JX0jrvPcPdVku5RGE8ZAAAAAACgKHXpmPimpDkFt+cm2VrMbLCZTTazyVVVVXVYHIBq1BWQ\nLWoKyB51BWSPukJTVfGLX7r7GHfv4+59OnZsdKduAQ0SdQVki5oCskddAdmjrtBU1aVj4n1JXQtu\nb55kAAAAAAAARalLx8QkSVub2ZZmtoGkAZIeyqZZAAAAAACgOSh7VA53/8LMTpX0mMJwoTe7+9TM\nWgYAAAAAAJq8sjsmJMndH5H0SEZtAQAAAAAAzUzFL34JAAAAAACQho4JAAAAAACQGzomAAAAAABA\nbuiYAAAAAAAAuaFjAgAAAAAA5IaOCQAAAAAAkBs6JgAAAAAAQG7omAAAAAAAALmhYwIAAAAAAOSG\njgkAAAAAAJAbOiYAAAAAAEBu6JgAAAAAAAC5oWMCAAAAAADkho4JAAAAAACQGzomAAAAAABAblrk\n3QBk4/rrr4/mJ598cjQfN25cND/qqKMyaxMAAAAAALXhiAkAAAAAAJAbOiYAAAAAAEBu6JgAAAAA\nAAC5oWMCAAAAAADkho4JAAAAAACQmzqNymFmMyUtlbRa0hfu3ieLRiHdH/7wh2h+6qmnljSfjTfe\nOIvmAAAAYB2uueaaaD5kyJB6bglQu1GjRkVzM4vm22+/fTQ/7LDDMmsTmocshgvd190XZTAfAAAA\nAADQzHAqBwAAAAAAyE1dOyZc0gQze9XMBscmMLPBZjbZzCZXVVXVcXEAJOoKyBo1BWSPugKyR12h\nqaprx8Se7v4dSQdL+oWZ9as5gbuPcfc+7t6nY8eOdVwcAIm6ArJGTQHZo66A7FFXaKrq1DHh7u8n\n/y+UNF5S3ywaBQAAAAAAmoeyL35pZm0krefuS5O/vyfpwsxa1sy9+OKL0fz000+P5htuuGE0v+OO\nO6L5AQccUF7DgBJ8/PHH0fzOO++M5qNHj47m77//fibtOfLII6P5oEGDSpoeaOwWL14czadPnx7N\n77rrrpLmf9VVV0XztKu6l6pLly7R/KWXXorm3bp1y2S5gCQtX748mp977rnR/L333ovmjMqBhmj4\n8OHRPO39u2XLltG8VatWmbWpktw9mo8cOTKab7DBBiXNf8KECdH8xBNPjOY/+MEPSpp/U1KXUTk6\nSxqfbKQtJN3l7n/LpFUAAAAAAKBZKLtjwt1nSNopw7YAAAAAAIBmhuFCAQAAAABAbuiYAAAAAAAA\nuaFjAgAAAAAA5KYuF79EBv71r39F8wEDBpQ0n8suuyyaH3300SW3CSjVihUronn//v2j+TPPPFPS\n/Pfdd99ovuOOO0bzbbfdNpqPHz8+mp9wwgnRPG1UG0brQGORtg2PGjUqmr/11luZLDft6u077RS/\nNNXnn38ezadNmxbNFyxYEM3nz58fzRmVA1lKG2Xj2muvjeavvPJKJZsD5Crt/Tstb2jSRuU466yz\nKrrcqqqqaN6cR+XgiAkAAAAAAJAbOiYAAAAAAEBu6JgAAAAAAAC5oWMCAAAAAADkho4JAAAAAACQ\nG0blqCczZ86M5gceeGA0/+CDD6L5lVdeGc1PO+20stoFZGHMmDHRPG30jS233DKap42+cf3110fz\nli1bFtG6r/zsZz+L5gMHDozmxx13XDS/5557onnaKCRApd11113R/OSTT47mn376aTRv3759ND/q\nqKOiedooG/369YvmaaNjfPHFF9G8a9eu0TxtJKC09fDd7343mgPlOP3006P5DjvsEM1btWpVyeYA\nmbruuuui+YQJEzKZ/6JFi6L5888/n8n80XhxxAQAAAAAAMgNHRMAAAAAACA3dEwAAAAAAIDc0DEB\nAAAAAAByQ8cEAAAAAADIDaNyZCztyuK//OUvo/n7778fzc8888xoPmTIkPIaVsPq1auj+Xrrxfuq\nzCyT5aJpuuaaa0qa/m9/+1s032abbbJoTqq07Xvs2LHRfNWqVdH8V7/6VTTfY489onmnTp2KaB1Q\nu7TRNG688cZovssuu0TzESNGRPO0bXijjTYqonXlSxtlo9R9zw9+8IMsmgNIkh5//PFonvYZ6o03\n3qhkc0r27rvvRvPFixdH87T3i7///e/R/IUXXiivYTWkje5z2GGHZTJ/lObnP/95SXmpnnjiiWj+\nve99L5P5l6p79+7RfOutty5pPtttt10033TTTaN52mhXzRlHTAAAAAAAgNzQMQEAAAAAAHJDxwQA\nAAAAAMgNHRMAAAAAACA3dEwAAAAAAIDc1Doqh5ndLOlQSQvdffskay/pXkndJc2UdKy7f1y5ZjYe\nV111VTQfP358NB8wYEA0v+KKKzJpz5o1a0pa7oEHHhjNTzrppEzaA0jSxIkTo3mlR+VIkzbiwMUX\nXxzN99tvv2h+xBFHRPOXXnqpvIYBNbRu3TqaP/XUU/Xckmyl7fPSRiFJu1p6z549M2sTkDaCVNoI\nT1n54IMPovmRRx5Z0nyWLFkSzVeuXBnNv/nNb0bzRYsWRfO33367pPak6dixYzTv1q1bNH/llVcy\nWS7yMXfu3IrOv0WL+NfbYcOGRfMTTzwxmn/rW9/KrE0oTjHvrLdIOqhGdq6kJ919a0lPJrcBAAAA\nAABKUmvHhLs/K+mjGvERkm5N/r5VUmlduAAAAAAAACr/GhOd3X1e8vd8SZ3TJjSzwWY22cwmV1VV\nlbk4AIWoKyBb1BSQPeoKyB51haaqzifJubtL8nXcP8bd+7h7n7RzyACUhroCskVNAdmjroDsUVdo\nqsrtmFhgZptJUvL/wuyaBAAAAAAAmotaR+VI8ZCkQZJGJ/8/mFmLGolZs2ZF82uuuSaa77DDDtH8\n/PPPz6xNMWlXvr3//vuj+bRp06L5CSecEM1btWpVXsPQpFx99dXR/Nhjj43m55xzTjRPq5PevXuX\n17A66tWrVzS/7rrrovnPf/7zaL5ixYponjYaCNBUTZo0KZr/9re/LWk+J598cjTfdNNNS24TkDYK\nxpQpU6L5jTfeGM0nT54czbfYYoto3qlTp2j+05/+NJqnjbIRDl7+T9OnT4/maQYNGhTNV69eHc0v\nueSSkuafJu10hL59+2Yyf+Rj6dKl0fzKK6/MZP5p7/djx46N5oceemgmy0Xl1HrEhJndLeklSdua\n2Vwz+2+FDokDzGy6pP2T2wAAAAAAACWp9YgJd/9hyl37ZdwWAAAAAADQzNT54pcAAAAAAADlomMC\nAAAAAADkho4JAAAAAACQm3JH5Wj2Ro+OX+9zzpw50Xzo0KHR/Nvf/nYm7fn888+j+fDhw0uaT+fO\nnaM5o29gXdKudHzBBRdE89/85jfR/OCDD47mN9xwQzQ//PDDi2hd7d58881ofu6550bziy++OJqn\nXRn9pptuiuannnpqEa0DGp81a9ZE88ceeyyaf/rpp9F8k002ieb77rtveQ0DItJGHnv66aej+c9+\n9rNoPnv27Gh+5513RvO0UTnatGkTze+7775onrbvWbBgQTRP069fv2ie9tk2bYS39957L5qvWrUq\nmh900EHR/Oabb47maByef/75aP7WW29lMv/PPvssmqfVSVq+9957R/Mf//jH0Xy99fhdv1JYswAA\nAAAAIDd0TAAAAAAAgNzQMQEAAAAAAHJDxwQAAAAAAMgNHRMAAAAAACA3jMpRi3feeSeajx07Npof\ncsgh0XzIkCGZtSkm7YrJd9xxR0nzOfLII7NoDiBJOvvss6N5z549o/mAAQOief/+/aP5D3/4w2h+\n4YUXRvOtttoqmi9evDia//Wvf43m2267bTQfPHhwNP/lL38ZzQcOHBjN27dvH82BxiJtJJrzzz+/\npPmkjYC14447ltwmYOLEidF88uTJ0XznnXeO5mnb5RVXXBHNS31PHzduXEnTV1qPHj2i+SuvvBLN\nf/GLX0TztM+km222WTTv2LFjEa1DQ5U20tqIESOiedqIbWmWL18ezW+//faS5nPbbbdF87Ttu2XL\nltH8jDPOiOZp23Hr1q2jeYsWzffrOUdMAAAAAACA3NAxAQAAAAAAckPHBAAAAAAAyA0dEwAAAAAA\nIDd0TAAAAAAAgNw038t+Fukvf/lLNF+5cmU0X7NmTSWbk+q+++7LZD4/+MEPMpkPsC6HHnpoNH/5\n5Zej+UUXXRTN77zzzmj+4IMPRvO0K6zvueee0TzN1KlTo/mll14azS+++OJontf7BVBpDz/8cEnT\nb7HFFtF80KBBWTQHkCTdcMMN0XzZsmXR/IQTTojmu+yySzS/6667ymtYI7VgwYJoXuqIcGhe0uoq\nbTSKtM96aZ/FsjJmzJiSpr/22mtLmj5tJLq0UUt69epV0vwbI46YAAAAAAAAuaFjAgAAAAAA5IaO\nCQAAAAAAkBs6JgAAAAAAQG7omAAAAAAAALmpdVQOM7tZ0qGSFrr79kk2UtL/SKpKJhvm7o9UqpF5\nOvDAA6N52pVjH3300Wh+9NFHR/Nhw4ZF8z59+kTz6dOnR/O0q/6nOemkk6J5p06dSpoPkKXtt98+\nmt9zzz3R/Pzzz4/maVfynzVrVjR/7rnnimjdVyZMmBDN27RpU9J8XnjhhWh+xBFHlDQfIC+vvfZa\nNE8b0crMovnZZ58dzTfccMPyGoZm7cILL4zmaaNF7LXXXtH8tNNOy6xNjdnIkSOj+W9/+9tofsYZ\nZ0TzUaNGRfP111+/rHahcerevXs0P/fcc0vK06SNzDZx4sRo/uKLL0bzZ555pqTlluruu+8uKT/2\n2GOjed++faP50KFDy2tYjoo5YuIWSQdF8ivdvXfyr0l2SgAAAAAAgMqqtWPC3Z+V9FE9tAUAAAAA\nADQzdbnGxKlmNsXMbjazr6dNZGaDzWyymU2uqqpKmwxACagrIFvUFJA96grIHnWFpqrcjonrJH1L\nUm9J8yRdkTahu49x9z7u3qdjx45lLg5AIeoKyBY1BWSPugKyR12hqSqrY8LdF7j7andfI+mPkuJX\n3QAAAAAAAFiHWkfliDGzzdx9XnKzv6Q3s2tSw9KrV69onjYawHnnnRfNx48fH83//ve/R/O0K6ym\nXTl22bJl0Xy99eJ9TxdddFFJ0wN5SruSf1p9Tpo0KZqnHfI4d+7caD58+PBonjb6Ts+ePaN5mmnT\npkVzRuVAQ7N8+fJonna1fneP5vvtt180P+WUU8pqFxCT9hktbV+S9tknbQS2piptpLjHH388mv/q\nV7+K5mkj2rVq1aq8hgElSPsMlZavWrUqmq9cuTKap41G8/rrr0fzRx7JZoyI++67L5qnjYKVNqrV\nqaeemkl7KqGY4ULvlrSPpA5mNlfS+ZL2MbPeklzSTEk/q2AbAQAAAABAE1Vrx4S7/zAS31SBtgAA\nAAAAgGaG4/YBAAAAAEBu6JgAAAAAAAC5oWMCAAAAAADkpnldbjhDI0aMiOY9evSI5uecc040nzNn\nTjSfMGFCeQ2roV+/ftG8S5cumcwfaEzSxvtOy9NGEEgblePEE0+M5g8//HA0f/bZZ6P5ueeeG82B\nvIwdOzaap23bG220UTT/yU9+klmbgKwsWbIkms+fPz+aN5bPUJMnT47m1113XTS//fbbo/lmm20W\nzX/0ox9F86222qqI1gENwwYbbFBSfvHFF0fzFStWRPOPP/44mqeNCHfsscdG89mzZ0fzzz77LJoP\nGTIkmjfkUTk4YgIAAAAAAOSGjgkAAAAAAJAbOiYAAAAAAEBu6JgAAAAAAAC5oWMCAAAAAADkhlE5\nMjZgwIBoftRRR0Xz1atXR/OpU6dG81133TWat2nTJprfcsst0RxA9lq3bh3NN99882i+ww47VLI5\nQMmmT58ezYcPH17SfM4+++wi7uQqAAAgAElEQVRoPnDgwJLbBFTaa6+9Fs0HDRoUze++++5o3r59\n+8zaFDNlypRoft9990Xzyy67LJp///vfj+YjR46M5mkjvDH6BvCVtNGo0vIZM2ZE87RRcNJG5WhK\nOGICAAAAAADkho4JAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuaFjAgAAAAAA5IZROerJBhtsUNL0\ny5YtK2n6tCu4duvWraT5AKg/m2yySd5NQDPl7tH80ksvjeal7pMOPfTQktsEZKVHjx7RvKqqKpov\nWbIkmj/++OPRPG0Etj/84Q/RPG2UmnfeeSeap0lr55AhQ6L5q6++Gs2/8Y1vRPNKjyqC5uXGG2+M\n5n/84x+j+XbbbRfNb7755szalIXnnnsumq9cuTKap70vPPXUU9E8rc5LlfY+2JBxxAQAAAAAAMgN\nHRMAAAAAACA3dEwAAAAAAIDc0DEBAAAAAAByQ8cEAAAAAADITa2jcphZV0m3SeosySWNcferzay9\npHsldZc0U9Kx7v5x5ZravFx22WUlTX/ggQdWqCUAirVgwYJo/uSTT0bzPffcs5LNAVKNGzcumt96\n660lzefHP/5xNN91111LbRKQmenTp0fzn/70p9G8bdu20fzll1+O5k888UQ032abbYpoXe1atmwZ\nzU8//fRovt9++0Xz7bffPpP2AOuyaNGiaH7JJZdE81mzZkXzt99+O5r369cvmvfq1auI1n3lscce\ni+ZPP/10NF9vvfjv988//3w0TxuVo9LatGkTzdNGFWrIijli4gtJQ929l6TdJP3CzHpJOlfSk+6+\ntaQnk9sAAAAAAABFq7Vjwt3nufs/kr+XSpom6ZuSjpBU/dPKrZKOrFQjAQAAAABA01TSNSbMrLuk\nnSVNlNTZ3ecld81XONUj9pjBZjbZzCZXVVXVoakAqlFXQLaoKSB71BWQPeoKTVXRHRNm1lbSOEln\nuPuSwvvc3RWuP/Ef3H2Mu/dx9z4dO3asU2MBBNQVkC1qCsgedQVkj7pCU1VUx4SZtVTolLjT3R9I\n4gVmtlly/2aSFlamiQAAAAAAoKkqZlQOk3STpGnu/r8Fdz0kaZCk0cn/D1akhU3c66+/Hs3TrvgM\noOGaMWNGNP/ss8+iOaPpIC9pVz8v1YgRIzKZT5p77703mh933HEVXS6apnPPjV+nfauttorms2fP\njuaHH354NE8bmalUF1xwQTQ/5ZRTMpk/kKW0USrmz59f0nw++eSTaJ42mk5WwoH//yl8Ba6cVq1a\nRfPu3btH80022SSaDx8+PJp369atrHblqdaOCUl7SDpR0j/NrPpb9DCFDok/mdl/S5ol6djKNBEA\nAAAAADRVtXZMuPvzktK6jOIDJwMAAAAAABShpFE5AAAAAAAAskTHBAAAAAAAyA0dEwAAAAAAIDfF\nXPwSFbRs2bJo/vnnn0fztm3bRvPjjz8+szYBKM+oUaNKmr5r164VagmwbpMnTy5p+vPOOy+ab7HF\nFtF85cqV0fyBBx6I5hdddFE0//3vf19E64DibLPNNiVNnzZax5tvvplFc4Am4cgjj4zm3/3ud6P5\ntGnTonlVVVVmbaqkNm3aRPOvf/3r0fzkk0+O5jvttFM0//73v19ew5oAjpgAAAAAAAC5oWMCAAAA\nAADkho4JAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuWFUjpx16tQpmm+00UbRfJdddonmu+++e2Zt\nAlCeN954I5qnjb6x4YYbVrI5QKqXXnqppOk/+uijaP6vf/0rmqeNFDVr1qxoPnz48Gi+9957F9E6\nAEBD8/TTT0fzOXPmRPMjjjgims+YMaOk5R5++OHRvG/fviXNJ03Pnj2j+X777ZfJ/JszjpgAAAAA\nAAC5oWMCAAAAAADkho4JAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuWFUjpxts8020fzTTz+t55YA\nqKtNNtkkmj/11FPRfOONN65kc4BU/fv3j+Y33HBDNL/22mtLyt09mg8ePDian3POOdEcANC0pI1U\n9o9//KOeW4KGhiMmAAAAAABAbuiYAAAAAAAAuaFjAgAAAAAA5IaOCQAAAAAAkBs6JgAAAAAAQG5q\nHZXDzLpKuk1SZ0kuaYy7X21mIyX9j6SqZNJh7v5IpRoKAPVthx12iOZbbrllND/wwAOjeY8ePTJr\nE5CFCy64IJq/8MIL0fzNN9+M5r17947mI0aMiOZpNQIAAJq3YoYL/ULSUHf/h5ltLOlVM3s8ue9K\nd/9d5ZoHAAAAAACaslo7Jtx9nqR5yd9LzWyapG9WumEAAAAAAKDpK+kaE2bWXdLOkiYm0almNsXM\nbjazr6c8ZrCZTTazyVVVVbFJAJSIugKyRU0B2aOugOxRV2iqiu6YMLO2ksZJOsPdl0i6TtK3JPVW\nOKLiitjj3H2Mu/dx9z4dO3bMoMkAqCsgW9QUkD3qCsgedYWmqqiOCTNrqdApcae7PyBJ7r7A3Ve7\n+xpJf5TUt3LNBAAAAAAATVExo3KYpJskTXP3/y3IN0uuPyFJ/SXFL9kNAI3U9773vWg+Y8aMem4J\nkK20X9neeOONem4JAABAcaNy7CHpREn/NLPXk2yYpB+aWW+FIURnSvpZRVoIAAAAAACarGJG5Xhe\nkkXueiT75gAAAAAAgOakpFE5AAAAAAAAskTHBAAAAAAAyA0dEwAAAAAAIDd0TAAAAAAAgNzQMQEA\nAAAAAHJDxwQAAAAAAMgNHRMAAAAAACA3dEwAAAAAAIDc0DEBAAAAAAByY+5efwszWyrprXpbYP46\nSFqUdyPqUWN/vt3cvWPejSgVddXkNfbn2+jqippq8hr78210NSVRV81AY3++1FXj0Ni3s1I19udb\nUl21qGRLIt5y9z71vMzcmNlkni/qAXXVhDW359tAUFNNWHN7vg0IddWENbfn24BQV01Yc3u+nMoB\nAAAAAAByQ8cEAAAAAADITX13TIyp5+XljeeL+tDc1jvPF5XW3NY5zxf1obmtd54v6kNzW+883yas\nXi9+CQAAAAAAUIhTOQAAAAAAQG7omAAAAAAAALmhYwIAAAAAAOSGjgkAAAAAAJAbOiYAAAAAAEBu\n6JgAAAAAAAC5oWMCAAAAAADkho4JAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuaFjAgAAAAAA5IaO\nCQAAAAAAkBs6JgAAAAAAQG7omAAAAAAAALmhYwIAAAAAAOSGjgkAAAAAAJAbOiYAAAAAAEBu6JgA\nAAAAAAC5oWMCAAAAAADkho4JAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuWnWHRNmNtPM9s9x+XPN\nbJ+8ll8pZra/mc0suP2Wme1Vxnz2MbOpmTYOFUddVYaZnWRmTyd/r29my8xsizLmM8jMHs28gago\n6qoy2F81b9RVZbC/ar6oqcpoLjVV0Y4JMxtgZhPNbLmZLUz+PsXMrJLLrSszezR5wZeZ2edmtqrg\n9vVlzvMOMxuZcTvPSN4AlpjZK2b2X0U+roWZefK6LEuK+HIzq8j24O7buvtzRbape8Hjnnb37SrR\nphrL7mlmfzGzKjP7KHn9t670cstFXa01z0zryswON7MXzWyxmc0zsxvMrG2Rj+2RbMPVz+k9Mzs7\nq7YVcvfV7t7W3WcX06Yaj73V3Q+uRLtqLHsjMxtnZrOS9bJnpZdZF9TVWvNkf1Vcm7oXPK5e9lfJ\n8o80s6nJ+njBzL5dH8stB3W11jwrUVedzOxuM/vEzD42s9uKfBz7q8iyC9bHMjMbVunlloOaWmue\nWX8GPK/GNrDCzFab2deLeCw1tfayy/oMWLGOCTMbKulqSZdL6iKps6SfS9pD0gYpj1m/Uu0phbsf\nnLzgbSXdKemy6tvu/vOa05tZi/puo5ntIekiSf0ltZN0u6QHSnxj2i55jt+TNEjSTyPLqffnloNN\nJD0gaVuF7fR1SeNzbVEK6qriNpZ0gaTNJG0naUtJo0uZQcFzPFHShRb55aCZ1JVLelbSQElVObdl\nnairymJ/lZ2kE+I2Sf+jsC7/JunBhrI9FqKu6sWDkuZI6iqpk6QrS3kw+6u1FbzGbd19VN7tqYma\nqngbLyrcBiRdIelJd/+4hHlQU0F5nwHdPfN/Cl/0lks6upbpbpF0naRHkun3Tx57W/IkZkkaIWm9\nZPqRku4oeHz35Im3SG4/rfDh5wVJSyVNkNShYPoTk3l+KGm4pJmS9i+ijRfXyPZPHjtM0nxJYyWd\nJOnpgmlaJG3rLukUSZ9LWiVpmaTxyTRzJf1S0j8lfSLpbkkbFrmOj5f0Yo117pI6FvHYL9tWkI2X\ndFVBu85O2rUyyTZPpqmS9J6kXxQ8trXCB82PJU2V9CtJMwvunytpn4JlnyfpXUlLJE2W9A1JLyZt\nWp6so6Or13PBfLaT9IykxUnbDim47w5J10h6NHntX5K0ZZnbb6ekLZtUoj6oq4ZbV5F2HivptSKn\n7SHJa2SvSTqjoN2nSHpH0jvJ/b0kPSHpI0n/LnxtJXWU9HBSJy9LuqR6XahGDSvU4JWSZifP+VlJ\nG0r6IJluWfJv18g63VOhDj+R9Iqk7xbc97xCR82LyWv/N0nty1iP8yXtmXcNUVfsr9TI91cK7ycP\n1lg/qyTtnXctUVf1XlffT7bN9cp4fdhf1bI+Gto/UVNrbUuq8GdASZY8r+Opqfr7DFipIyZ2T1bI\ng0VMO1BhZW+ssAJ+r1BAW0naW9KPJP2khGUPTKbvpNB7eJYkmVkvhUI9UeGDxaYKH17KtbmktpK2\nUNjQUrn7HyTdK2mUh560/gV3HyvpAIXnu0vSvurzhxab2W4ps/2rpFZmtmvSG/pTSa+6e8m/TJrZ\ndgq9ra8VxAMkHSypXXLI7MOSJkn6ZtLes81sv2TaCxV667dS2FEOWsfizpZ0jKSDFH7tOUnSZ5L6\nJfdvl6yjcTXauEHShr8qFOuZku41sx4Fkw1U+BDZXqE4Lyp4/KNmdlatKyPoJ2muu39S5PT1hboq\nUKG6qqmfwpeXkliwl6SeWruuDlfYMexg4RSRxxU+LHRS+PI2xsy2Taa9TmFH0EXSYEV+IS5wpaQd\nJX1XYfsfJmlN0n75V78ATKrRzg4KNXWFwmv3e0mP1DhscaBCTXeW1EZhh1/9+Klmdmwx66QBo64K\nsL9aS0PdX8WONNl+HdPngboqUKG62k3SW5LuMLMPLZwiVfIpc+yv1lrGXDObY2Y3m9mm65o2B9RU\ngXr4DLivwvt+yUdQU1Plq1THRAdJi9z9i+rAvjpve4WZ9SuY9kF3f8Hd1yj0fA2Q9Gt3X+ruMxVW\n1oklLHusu7/t7isk/UlS7yQ/RtLD7v6su69U+ECwpuxnKH0haaS7r0qWVa6r3H2+u3+o8EGmt/Tl\n+UPt3P3llMctUSiWFyWtlPRrhQ23FFPMbLHCm9x1CsVR7Wp3n5s8t90lfc3dRyXP9x1JNym8VlJ4\nA7jY3T9291mS/m8dyzxJ0jB3n+7ua9z9dXf/qIi2Vh+mdrm7f+7uTyj82jSgYJr73X2yu3+ucJhY\n9WsvD4eQ/a62hVi4kMw1Kii8BoS6Kl65dfUlMztY4Q35/FIWnNTUR5LGSBrq7s8U3D0qqZMVko6Q\n9La73+buX7j7q5L+LOkYM2sp6UhJ57n7p+4+ReFX3tjy1pf0Y0lD3H1e8hyfT+qgNodJmurudydt\nuF3SDEmHFExzU1Kvn0q6T2vX1Xbu/qeiVkzDRV0Vj/1V/vurxyX9PzPrl3SAnKfw61nrItpVn6ir\n4pVbV5srdMg9pvDl5WpJD5lZ+2IXzP7qSwsl9ZHUTVJfSV/X2u8xDQE1Vbw6fwZU+DJ+X7ItFY2a\nqptKnePyoaQOZtaiuoDc/b+k0BuptTtE5hT83UFSS4VDZ6rNUvjVo1jzC/7+VKHnTQo9eV8uy92X\nm9mHJcy3pgXuvqoOj69Ws73F7lAGSzpB4TCgGQq/6DxiZju5+4Ii57Fj8gYVU/i6dJO0RVJs1dZX\nOLxLCufjF05f+PrV1FXh0MNSfUPSbPdwTFDBcgq3jbTXvihm1knhELWr3f2+MtpYadRV8cqtK0mS\nhQvz3SbpKHcvaXt193bruLtmXe1Ro65aKBzi2FmhxmrWVd/IPDsrfAkqt65q1mumddUIUFfFY39V\nnIrtr9x9qpn9VKFzprPC+9RbCocvNyTUVfHKrasVCoeE35rcvtPMRih0zv21mBmwvwrcfYmkV5Ob\n88zsNEmzzax1qV9MK4iaKl5dPwO2VThFr+SLRFJTdVOpIyZeUvhV5Igipi3ccS9S6NnrVpBtIen9\n5O/lWvtXgS4ltGmewocMSZKZtVY4bKVcXuN2bW2rOX1d9Zb0UNKLtdrd/6qw/nbPaP6F7Z0jaXrS\ny1j9b2N3Pyy5f74K1q3Ca5ZmjqRv1bK8mA8kdTVb62JphdtGnSSH7D2h8CvWb7OYZwVQV5WvK5lZ\nH4Ve60Hu/nTGs69ZV0/WqKu27n6qpAUKvzoUU1cLFM6xLLeuutXIMqurRoK6Yn+VpkHur9z9T8kv\nVR0kXZzMe3IW884QdVX5upoSmWeWy2jO+6vqtjSkkS6oqXr4DJg4WmFbfT7j+TbnmipKpYbbWqxw\nsYw/mNkxZraxma1nZr0Vzk9Je9xqhUOELkke003hkPo7kklel9TPzLYws00UDgct1v2SDjWzPZPD\nHy9Uts//DUk7mtkOZraR/vPw7wUK5zplZZLC8+menMt0oMJGOVX6crzbdzJa1kuSVpnZUDNrlZyj\ntYOZ7ZLc/ydJw8ysXXIqxKnrmNeNki42s28l7e5tZu2T1/5Dpa+jFxUO8RpqZi3N7P8pnB98b12f\nXLItTZD0lLuPqOv8KoW6qnxdmdlOCheMOsXdH4ncf7GZPZHR4h6StJ2ZDUy26ZZm1tfMtk0Owfuz\npAssDLm0vVIOu0xe31skXWVmXZL63CM5FHChJDeztHX0cNKG4ywMgThQ4QJORf3aVhsz29DMWiU3\nNyj4u8GgrthfrWNeDW5/JUlmtkuyjXaS9EdJ49x9ehbzzgp1VS91NU5SZzM7PtnOj1M4V/0lif1V\nKcxsNzPbJtlGOyqcFvOkuy+v67yzQk3VS01VGyTp1hpHvVFTJSrnM2DFhgt198sUNvxzFDacBZJu\nULgC9ovreOhpCj1kMxR6qu6SdHMyz8cVduxTFA65eriE9kyV9ItkfvMUrsid2aGP7v4vSaMUDhd9\nS+GKqIVulLSThXGm769tfsmGtczM0n5RGqswxOWzCldSvVLSfxd8OOmqcAXdOksOGfu+wiFEMxV6\nX2+Q9LVkkvMV1ulMhfNo13Ve3uUKxfakwnnHYyRVb6jnS7rLwvlyR9Vow0qFc6GOSJZ/jaSBxX4Y\nM7MJZnZOyt3HSPqOpJNs7fGLv1HMvOsTdVXxujpLobf/loLt4I2C+7Osq08kHahwiPs8hV9yL1W4\nuJUknaxwnusChXPkx65jdmdKmqbw+n2ksM7M3Zcm85yY1FWfGm2oUrgY068UvmidKelQL3JoLDN7\nK/kwnOZdhcONOyvU/Aozq8uFsSqCumJ/laIh7q+kcF2MTxRqfqHCcIENDnVV2bpy90UK29ivFbaH\nsyQd7l9dB4X9VYFa9lc9FH6gWqrwZXiZwsUIGxRqquL7quprzfVTfN9ATRWoxGdAq9EZhCbCzJ6U\ndLK7v513W4CmwsymKAzLV/SY1gDWjf0VkD32V0C2qKnKo2MCAAAAAADkpmKncgAAAAAAANSGjgkA\nAAAAAJAbOiYAAAAAAEBuWtTlwWZ2kMKQOutLutHdR69r+g4dOnj37t3rskigYl599dVF7t4x73aU\nirpCQ9YY64qaQkPWGGtKoq7QsFFXQPZKrauyOybMbH1J10o6QGFomElm9lAytEtU9+7dNXny5HIX\nCVSUmc3Kuw3loK7QkDXGuqKm0JA1xpqSqCs0bNQVkL1S66oup3L0lfSOu89w91WS7lEYTxkAAAAA\nAKAodemY+KakOQW35ybZWsxssJlNNrPJVVVVdVgcgGrUFZAtagrIHnUFZI+6QlNV8YtfuvsYd+/j\n7n06dmx0p24BDRJ1BWSLmgKyR10B2aOu0FTVpWPifUldC25vnmQAAAAAAABFqUvHxCRJW5vZlma2\ngaQBkh7KplkAAAAAAKA5KHtUDnf/wsxOlfSYwnChN7v71MxaBgAAAAAAmryyOyYkyd0fkfRIRm0B\nAAAAAADNTMUvfgkAAAAAAJCGjgkAAAAAAJAbOiYAAAAAAEBu6JgAAAAAAAC5oWMCAAAAAADkho4J\nAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuaFjAgAAAAAA5IaOCQAAAAAAkBs6JgAAAAAAQG7omAAA\nAAAAALmhYwIAAAAAAOSGjgkAAAAAAJAbOiYAAAAAAEBuWuTdAJTGzKL5UUcdFc3dPZpvt9120fyi\niy4qr2EAAAAAAJSBIyYAAAAAAEBu6JgAAAAAAAC5oWMCAAAAAADkho4JAAAAAACQGzomAAAAAABA\nbuo0KoeZzZS0VNJqSV+4e58sGoV0aaNy/PnPf47maaNyPPjgg9F85513juZpo34ATcHs2bOj+THH\nHBPNJ02aVNL8zzrrrGh++eWXlzQfoNKWLl0azf/v//6vpPlMmDAhmr/88svR/Mwzz4zmQ4cOjeab\nbrppSe0BAAANWxbDhe7r7osymA8AAAAAAGhmOJUDAAAAAADkpq4dEy5pgpm9amaDYxOY2WAzm2xm\nk6uqquq4OAASdQVkjZoCskddAdmjrtBU1bVjYk93/46kgyX9wsz61ZzA3ce4ex9379OxY8c6Lg6A\nRF0BWaOmgOxRV0D2qCs0VXXqmHD395P/F0oaL6lvFo0CAAAAAADNQ9kXvzSzNpLWc/elyd/fk3Rh\nZi1D1PXXX1/S9CNGjIjmixbFr1d66aWXRnNG5UBj8uKLL0bzUaNGRfN58+ZF89deey2ap42O065d\nu2g+cODAaA7k5a233ormffvGf19YtmxZSfNPGxEqrXZ++9vfRvO00UDSavnUU08tonUAAATTpk2L\n5t/5znei+Q477BDN00adWm89LulYrLqMytFZ0vjkQ0YLSXe5+98yaRUAAAAAAGgWyu6YcPcZknbK\nsC0AAAAAAKCZ4dgSAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuanLxS+Rg8GDB5c0/T/+8Y9o/sc/\n/jGL5gD1oqqqKprfe++90TxtNJolS5Zk1qaYxYsXR/O77747mu+8886VbA6QOgLTySefHM1LHX2j\n0pYvXx7NzznnnGg+YcKEaP7QQw9l1iagqfrwww+j+aefflrSfObPnx/Nn3322Wi+6aabRvPjjz8+\nmrds2bKk9gBS+ghsAwYMiOYbbLBBNE/b/zD6Rt2xBgEAAAAAQG7omAAAAAAAALmhYwIAAAAAAOSG\njgkAAAAAAJAbOiYAAAAAAEBuGJWjmXL3aL7XXnvVc0vQlKWNgpF25e/x48dH89tuuy2aT5kypbyG\nAU3MwoULo3naVe2feeaZSjan4lauXBnN00bwAZqC559/PppPnTo1mqfVedq+c+7cudH8k08+KaJ1\n2UsbReHXv/51PbcEjUnadj969OhonlYP999/fzQ/+uijy2sYasUREwAAAAAAIDd0TAAAAAAAgNzQ\nMQEAAAAAAHJDxwQAAAAAAMgNHRMAAAAAACA3jMrRxKWNcmBm0bx///6VbA6aqBUrVkTzE044IZo/\n/PDDlWxOqsMOOyyab7jhhtE87YrMQEOT9l7/1FNPZTL/li1bRvNLLrkkmvfr1y+ajxs3Lppffvnl\n5TUMaEA+++yzaP7CCy9E87S6TauTZcuWRfNevXpF83322SeaDxo0KJrvtNNO0bxLly7RPCuvvfZa\nNP/Od74TzRmVo3FbvHhxNG/Xrl00TxtJ8JprronmI0eOjOann356NP/3v/8dzT/44INojsrhiAkA\nAAAAAJAbOiYAAAAAAEBu6JgAAAAAAAC5oWMCAAAAAADkho4JAAAAAACQm1pH5TCzmyUdKmmhu2+f\nZO0l3Supu6SZko51948r10yUK22UjTFjxkTzvfbaq5LNQROVdiXyvEbf2G233aL5rbfeGs2ffPLJ\naM6oHGgsxo4dW9H5b7PNNtF86NChJc1n4sSJWTQHyNXMmTOjeVo9pO0Lt99++2g+evToaH7IIYdE\n8w4dOkTzxuLuu++O5gcddFA9twRZWrRoUTQ/66yzonnaSG4XXXRRNH/vvfei+e233x7NDz300Gie\n9hkQ9a+YIyZukVTzneFcSU+6+9aSnkxuAwAAAAAAlKTWjgl3f1bSRzXiIyRV//R4q6QjM24XAAAA\nAABoBsq9xkRnd5+X/D1fUue0Cc1ssJlNNrPJVVVVZS4OQCHqCsgWNQVkj7oCskddoamq88Uv3d0l\n+TruH+Pufdy9T8eOHeu6OACiroCsUVNA9qgrIHvUFZqqcjsmFpjZZpKU/L8wuyYBAAAAAIDmotZR\nOVI8JGmQpNHJ/w9m1iKsU9ohW5deemk0Hz9+fDTv1atXZm0CSpV25eU77rijpPkcfvjh0fz444+P\n5u3atYvmd955Z0nLBZqqnj17RvMHH8xmN1/pWuvUqVNF54+maenSpdH8sssui+ZXXHFFNE/bt/3z\nn/+M5mmj3TRVt9xySzR/4oknovljjz1Wwdag0q699tponjZqRtrIaWmj0aSNprH11lsX0bqvMCJh\nw1HrERNmdreklyRta2Zzzey/FTokDjCz6ZL2T24DAAAAAACUpNYjJtz9hyl37ZdxWwAAAAAAQDNT\n54tfAgAAAAAAlIuOCQAAAAAAkBs6JgAAAAAAQG7KHZUDGZk1a1Y0TxuXOG3Ugquuuiqat27dOpo/\n88wzRbQOqJuuXbtG87Tt/oMPPihp/htvvHE0b9OmTUnzefTRR0uaHmiqevToEc233HLLkubzl7/8\nJZq//vrrJbepFKeffrv6Tu8AACAASURBVHpF54/GbcmSJdE8bYSnd999N5rfe++90fywww4rr2FN\nzHPPPRfNH3nkkWg+ceLEaN6yZcvM2oT6179//2jetm3baJ42+kbaKBvrr79+eQ0r0po1ayo6f/wn\njpgAAAAAAAC5oWMCAAAAAADkho4JAAAAAACQGzomAAAAAABAbuiYAAAAAAAAuWFUjpz17ds3ml9x\nxRXRfPTo0dHczKL5sGHDovm3v/3tIloHFCdt9Jd77rknmq9cuTKad+nSJbM2xYwdOzaar169uqLL\nBbLyxhtvRPO0kW5KlTaSTqleffXVaL5q1apM5r/ttttG82222SaT+aNxmz9/fjRPGyWgXbt20Tyt\n3tq3b19ew5qJnXbaKZpfe+210ZzRN5qmHXfcsaQ8L7vttls0/93vfhfNhwwZEs3TvouheBwxAQAA\nAAAAckPHBAAAAAAAyA0dEwAAAAAAIDd0TAAAAAAAgNzQMQEAAAAAAHLDqBz15IEHHojmCxcujOaj\nRo0qafqePXtG87RROYAsbbjhhtF89913r+eWrNsJJ5wQzU855ZRo/sUXX5Q0/7RRRdLqGSjVjBkz\nonnavqFUn3zySTT/7LPPovmFF14YzUsdQapUaaOHbL755pnMH43bhAkTonna9v3oo49G87TROkqV\nttwPP/wwmm+11VaZLDcvX/va1/JuAlC0ffbZJ5qfdNJJ0TytnrN6v2jOOGICAAAAAID/z96dh0lR\nXu0fv48sboALu4rw4hYRFRMEjIZFMGrUAEqMIKgxvkRN/AXjjhsqxn17k6jBiIJoIkZRo7gHYzTR\niLuIxo3NsIwogoIKcn5/VI02k6eYrp7qqVm+n+viYubu6qqnl9PVfaa6HuSGxgQAAAAAAMgNjQkA\nAAAAAJAbGhMAAAAAACA3NCYAAAAAAEBuqp2Vw8wmSjpY0hJ37x5n4yT9r6SKeLGx7j69XIOsi2bP\nnh3M77777mB+2WWXBfOkM5QPGzYsmM+aNSuY33vvvcF8/Pjxwfycc84J5kBD8NprrwXzcePGBfO0\ns28k2WCDcK+3aVMmQEI2hg4dGsx79uwZzJ9//vlU658yZUqqPIm7p1o+raR9GyBJU6dODeY/+tGP\ngnm5z6Y/atSoYP63v/0tmPft2zeYH3rooanyli1bBvOkfRXQGCXNIpM049yMGTOCedL+GcUr5pXp\nVkkHBPJr3L1H/K9RNSUAAAAAAEA2qm1MuPtTkj6qhbEAAAAAAIBGpibHcv3CzF41s4lmtkXSQmY2\n2sxmmtnMioqKpMUApEBdAdmipoDsUVdA9qgrNFSlNiZukLSdpB6SFkq6KmlBd5/g7j3dvWfbtm1L\n3ByAQtQVkC1qCsgedQVkj7pCQ1VSY8LdF7v7V+6+VtJNknplOywAAAAAANAYlHSqeDPr6O4L41+H\nSno9uyHVLXPnzg3mZ599djCfNm1aMO/Xr18wnzNnTjAfMWJEMP/ss8+Cebdu3YL5ueeeG8y7dOkS\nzEeOHBnMgfok6dDGpPrs379/MH/yySczGhFQXkkzPCXlealr40HDtHjx4mD+wAMPBPMLLrignMPR\n/fffH8znz58fzB988MFgfuONNwbzY489NpgPHjw4mP/mN78J5p06dQrmQGOUNIvPRRddFMyT6o1Z\ncIpXzHShf5TUX1IbM1sg6XxJ/c2shySXNEfSz8o4RgAAAAAA0EBV25hw9+GB+OYyjAUAAAAAADQy\nHFsCAAAAAAByQ2MCAAAAAADkhsYEAAAAAADITUmzcjQmRx11VDB/+umng3m7du2C+dVXXx3Mt912\n22Depk2bYL5y5cpgvvPOOwfzoUOHBvOLL744mG+yySbB/NBDDw3mQF3UvHnzYD5mzJhgnlQ/aWfl\nGDt2bKrlgaycccYZwXzYsGG1PBIgf5MmTQrmPXr0COYnnnhiMB83blwwT3qvl1bSLBjHH398MD/u\nuOOC+UMPPRTMb7rppmDevXv3YH733XcH80GDBgVzoC566aWXgvm9994bzD/++ONgvmDBglTr79y5\nczCfPHlyMB8wYEAwb8w4YgIAAAAAAOSGxgQAAAAAAMgNjQkAAAAAAJAbGhMAAAAAACA3NCYAAAAA\nAEBumJUjVlFREcyfeuqpYN6vX79gnvYs/mklzZqR5Nvf/nYwTzrzctKZprt06ZJq/UCe9tlnn2B+\nyy23BPOf/exnmWw3aXYPoNy+//3vB/NHH300mF9//fWp1v/aa68F83fffTfVerJyzTXXBPM77rij\nlkeCuqhbt27B/LrrrgvmSTMq/elPfwrmP/rRj4L5qFGjgnnSPimtpk3Db9sPOeSQVPlpp50WzJPG\nnzQLQYcOHYI5UBumTJkSzH/yk58E8zVr1qRa/3777RfMmzVrFsyXLFkSzHfYYYdU223MOGICAAAA\nAADkhsYEAAAAAADIDY0JAAAAAACQGxoTAAAAAAAgNzQmAAAAAABAbpiVIzZt2rRgbmbBfOjQoeUc\nTm5uu+22YP7GG28Ec2blQF3073//O5gvW7Ysk/UPGTIkmPfs2TOT9Sed2XnlypXBPGnWHDQem266\naTAfOHBgqjzJ7Nmzg3n37t1TrScrS5cuzWW7qN9OOOGEVPlVV10VzJ944olgfuCBBwbzzz//PJin\nrcO0Fi9eHMxffvnlYH788ccHc2bfQF2UNDvOhhtumGo9SbNvbLbZZsH8ggsuCOaXXXZZMO/YsWOq\n8TRmHDEBAAAAAAByQ2MCAAAAAADkhsYEAAAAAADIDY0JAAAAAACQGxoTAAAAAAAgN9XOymFmnSRN\nltRekkua4O7XmdmWku6U1EXSHEmHu/vH5RtqebVp0yZV/vvf/z6Yd+rUKZgfeuihpQ2sTO65555g\nfthhhwXzpNlJRo4cmdmYgKz069cvmCedoTytOXPmBPPLL788mO+9997BfPny5cH8tddeC+aTJ08O\n5lOnTg3mvXv3DuZAWltvvXXeQ1jHiy++GMxfeumlYL7HHnuUczhooE455ZRUeUVFRTCfO3duMH/l\nlVdSjeeZZ54J5kn7mCRJ+4Zu3bqlWg+Qp6TZN5Jm68jKuHHjgvnFF18czB944IFgPnjw4KyG1GAU\nc8TEGkmnuHs3SX0k/dzMukk6U9IT7r6DpCfi3wEAAAAAAIpWbWPC3Re6+4vxzyskzZa0taTBkibF\ni02SNKRcgwQAAAAAAA1TqnNMmFkXSXtIek5Se3dfGF+0SNFXPULXGW1mM81sZtIhbgDSoa6AbFFT\nQPaoKyB71BUaqqIbE2bWQtLdksa4+zpfjHZ3V3T+if/i7hPcvae792zbtm2NBgsgQl0B2aKmgOxR\nV0D2qCs0VEU1JsysmaKmxO3uXnnWxMVm1jG+vKOkJeUZIgAAAAAAaKiKmZXDJN0saba7X11w0f2S\njpZ0afz/fWUZYS1JmjVj3rx5wfwPf/hDMD/66KOD+ZtvvhnMx44dW8ToSjd+/PhgftlllwXzpNk3\nzjnnnMzGBJTbtddeG8yHDx+eyfpffvnlVPlmm20WzDt06BDMDz/88GA+cODAYM6Z1NHYfPTRR8H8\n44/r7eRgaACS/nqdlPfs2TPV+n/605+mHhOA2nHssccG8zPPDM8Pwawc/63axoSkvSWNkvSamVW+\n6x6rqCEx1cx+KmmupPA7aQAAAAAAgATVNibc/WlJ4T+jS+E/3wEAAAAAABQh1awcAAAAAAAAWaIx\nAQAAAAAAckNjAgAAAAAA5KaYk182amPGjAnm+++/fzA/8MADg/no0aMzG1PIqFGjgnnSbCBt2rQJ\n5pMmTQrmSbOWAHVRXZvXe8899wzmQ4YMCeZLloRnX77iiiuCecuWLUsbGAAAAGrsggsuCObbb799\nMH/99deDeffu3TMbU33DERMAAAAAACA3NCYAAAAAAEBuaEwAAAAAAIDc0JgAAAAAAAC5oTEBAAAA\nAAByw6wcJdp5552D+W233VbW7c6ePTuY33vvvcH8rLPOCuZJs4QkzdYB1CetW7cO5gcddFAwb9as\nWTC/4YYbgnnHjh1TjadHjx7B/MQTTwzmkydPDuZr1qxJtV0gK2YWzJs3bx7Mv/jii3IORzvttFMw\n33HHHcu6XQAAQpI+Q+22227B/JRTTgnmjzzySGZjqm84YgIAAAAAAOSGxgQAAAAAAMgNjQkAAAAA\nAJAbGhMAAAAAACA3NCYAAAAAAEBumJUjY9/73vfKuv6k2UBWrFhR1u0C9cnuu+8ezP/yl78E85Ej\nRwbzpDMsJ81qM3Xq1GA+fPjwYJ7kqKOOSrU8UG4tW7YM5g8//HAwHzBgQCbb7d69ezBPmnFqm222\nyWS7AACk0bRp+GP1tGnTgnmvXr2C+fz584N5p06dShtYPcIREwAAAAAAIDc0JgAAAAAAQG5oTAAA\nAAAAgNzQmAAAAAAAALmhMQEAAAAAAHJT7awcZtZJ0mRJ7SW5pAnufp2ZjZP0v5Iq4kXHuvv0cg0U\nAMplypQpqZa/8cYbU+VAQ9WvX79gvnbt2loeCQAAdU/79u2D+SGHHBLMN91003IOp04rZrrQNZJO\ncfcXzaylpBfM7LH4smvc/cryDQ8AAAAAADRk1TYm3H2hpIXxzyvMbLakrcs9MAAAAAAA0PClOseE\nmXWRtIek5+LoF2b2qplNNLMtEq4z2sxmmtnMioqK0CIAUqKugGxRU0D2qCsge9QVGqqiGxNm1kLS\n3ZLGuPtySTdI2k5SD0VHVFwVup67T3D3nu7es23bthkMGQB1BWSLmgKyR10B2aOu0FAV1Zgws2aK\nmhK3u/s9kuTui939K3dfK+kmSb3KN0wAAAAAANAQFTMrh0m6WdJsd7+6IO8Yn39CkoZKer08QwQA\nAAAAoGH47W9/m/cQ6pxiZuXYW9IoSa+Z2ctxNlbScDProWgK0TmSflaWEQIAAAAAgAarmFk5npZk\ngYumZz8cAAAAAADQmKSalQMAAAAAACBLNCYAAAAAAEBuaEwAAAAAAIDc0JgAAAAAAAC5oTEBAAAA\nAAByQ2MCAAAAAADkhsYEAAAAAADIDY0JAAAAAACQGxoTAAAAAAAgN+butbcxsxWS3qq1DeavjaQP\n8x5ELarvt7ezu7fNexBpUVcNXn2/vfWurqipBq++3956V1MSddUI1PfbS13VD/X9eZZWfb+9qeqq\naTlHEvCWu/es5W3mxsxmcntRC6irBqyx3d46gppqwBrb7a1DqKsGrLHd3jqEumrAGtvt5ascAAAA\nAAAgNzQmAAAAAABAbmq7MTGhlreXN24vakNju9+5vSi3xnafc3tRGxrb/c7tRW1obPc7t7cBq9WT\nXwIAAAAAABTiqxwAAAAAACA3NCYAAAAAAEBuaEwAAAAAAIDc0JgAAAAAAAC5oTEBAAAAAAByQ2MC\nAAAAAADkhsYEAAAAAADIDY0JAAAAAACQGxoTAAAAAAAgNzQmAAAAAABAbmhMAAAAAACA3NCYAAAA\nAAAAuaExAQAAAAAAckNjAgAAAAAA5IbGBAAAAAAAyA2NCQAAAAAAkBsaEwAAAAAAIDc0JgAAAAAA\nQG5oTAAAAAAAgNzQmAAAAAAAALmhMQEAAAAAAHJDYwIAAAAAAOSmUTcmzGyOmQ3KcfsLzKx/Xtsv\nFzMbb2a3xj93NbNPS1zPuWZ2Y6aDQ9lRV+VhZseZ2ZPxz03M7FMz27aE9RxtZg9lPkCUFXVVHuyv\nGjfqqjzYXzVe1FR5NJZ9VVkbE2Z2hJk9Z2afmdmS+OcTzczKud2aMrOH4hfRT81stZl9WfB7SQ+m\nmU0xs3EZD7Vy3ZPNzM2sS5HLDzKztfHtWWFmb5rZ0eUYm7u/5+4tihzTnCrXvcjdjy/HuALbb2dm\nfzSzT8zsYzObXBvbLQV1tc46M60ri5xnZvPMbLmZ3WFm1T5/4+tuH9dh5W1638xOy2pshdz9K3dv\n4e7zihlTletOcvcDyzGu9Yzjwvi+6V+b202Dulpnneyvqh/TnCrXrZX9VU1eo/JAXa2zzqz3V+cW\njOlTM1tlZl+Z2RZFXJf91brb3tjM7jazufH9sk+5t1kqamqddWZdU4X7m8p/R5ZwXfZVJb4+la0x\nYWanSLpO0hWSOkhqL+l4SXtLap5wnSblGk8a7n5g/CLaQtLtki6v/D30YJpZ09of5dfb7i+pSwlX\nnRffvlaSzpZ0s5ntFFh/bretlt0nab6kTpLaSbom3+GEUVdld6ykIyTtJWlrRfVxXZoVFNzGUZIu\ntMBfDhpRXcnMdpQ0RNKSvMeShLqqHeyvMlHj16jaQl2VfYwXFYyphaSrJD3h7h+nWAf7q4hLekrS\nCEkVOY8lETVVK+YV1pW73572umJfVfrrk7tn/k/SZpI+k3RYNcvdKukGSdPj5QfF152s6IVhrqRz\nJG0QLz9O0pSC63dR9GLSNP79SUkXSXpG0gpJj0pqU7D8qHidSxU9YeZIGlTEGMdXyQbF1x0raZGk\nWyQdJ+nJgmWaxmPrIulESaslfSnpU0nT4mUWSPqVpNckfSLpj5I2THE/N5P0iqTdK7dV5PUGSZpT\nJftY0YeH7eN1/UTSPEl/jS/fW9KzkpZJellS34LrdpX09/g+fyR+TG+NL9s+epp9vWzr+D5dGG/z\n7vgxXyVpbXz/fKqoOTC+cj3xdYdKmhWP4a+Sdiq4rOT7UtIPJL1b+Tyrq/9EXUllritJ90o6ueD3\nvpJWStqoiOuu81yPs5ckjSkY94mS3pH0Tnx5N0mPS/pI0puFj62ktpIekLRcUe1dXHlfFN4P8e+b\nKGqmzYtv81OSNpT0n3i5yrraM3Cf7iNpZny9f0nqXXDZ05IukPSP+LF/WNKWKZ+3j0n6fvy49M+7\njqgr9leq3/urkl+jqKuGV1cF27L4dh1Z5PLsr5Lvm0WS9sm7hqipXN4D/tf+JsXjw74q+b4p+vWp\nXEdM7KXoRea+IpYdoegFrKWiF5XfKLozu0rqJ+koRQ9ksUbEy7dT1D08VZLMrJuiB3WUpK0UPYjb\npFhvVdtIaiFpW0XFkcjdr5d0p6Rfe9Q5Glpw8eGS9lN0e78Tj6/yO3nLzKzPelZ9qqKdxKxSb4SZ\nbWBmw+Lb8lrBRX0lfUvSQWbWSdL9ks6XtKWkMyXdY2at42XvVFRYbSRdUnkbEtyh6HHppugxus7d\nP5F0iNbtUq7z11Uz21nSbZJOUrQDfFzS/WbWrGCxUu/LPpLekjTFzJaa2b/q6GF81FWBMtaVVfl5\nY0nbpbkRFvmepJ0Vvdmr9ENFb7Z2tejw68cUvVloJ+lISRMKuus3KNohdZA0WtFfSpNcI2k3Sb0V\n1ehYRTujvtI3fxVz9+erjLONpAcVdbJbK3qeTK9yqN0ISUcr+svMpop2UpXXn2Vmh6/nfhguabm7\nP7qeseeNuirA/moddXF/JWXwGlULqKsCZayrSgMkbS5pWtobwf6q3qCmCpSxprYys8Vm9p6ZXWVm\nm6S9Eeyr/kvRr0/laky0kfShu6+pDMzsH/ENWGVmfQuWvc/dn3H3tYo6X0dIOsvdV7j7HEUvQOt7\nMKq6xd3/7e6rJE2V1CPOh0l6wN2fcvcvJJ2r6IWwVGskjXP3L+Ntlepad1/k7ksVdZt7SF9/J29z\nd382dCUz66zohX9cidvd1syWSfpQUYfzSHd/t+Dy8919ZXzbjpJ0v7s/4u5r3f1hRX/5OsDMuir6\nC9j57v6Fuz+pqEsbGnMnSQMlneDuH7v7and/qsjxHhGP4a/uvlrSpYpeZHsXLFPSfanohfBARR3J\nDooOk7vfzLYscmy1hboqXqnPhYcljTazzma2uaTT47zoHVNcVx9JmiDpFHf/W8HFv46f+6skDZb0\nb3ef7O5r3P0FRX8NHRbvFIZIOjeuw1cV7TxC22si6RhJ/8/dF8a38em4TqpziKRZ7v7HeAy3SXpP\n0kEFy9zs7m+7+0pJd+mbx17uvou7T00YVytFf2U5uYhx5Im6Kh77q+KUc39V49eoWkJdFa/U50Kh\noyXdFb9OF439Vb1CTRWv1JqapWgf0VHRh/E+ir42Uyz2VWFFvz6V6zsuSyW1MbOmlQXk7t+VorOl\nat2GyPyCn9soOtxzbkE2V9H3KIu1qODnlYq6VVLUyft6W+7+mZktTbHeqha7+5c1uH6lquMt9sPw\n/yl6wq4o8btK89y9y3ouL3xcOksabmaF3chmit4gbSVpaZUn21xFnbeqOil6Uf2khPFupYLnhbuv\njZ9Lhc+NUu/LVYoOVZwU/367mZ2jqDv9YAljLRfqqnilPhduUtSoekrR/XmNoq/6LCh2w+6++Xou\nrlpXe8c7sUpNFR2O115SkyrLz5XUK7DO9oo65e8GLqvOOnVVsJ311VWxJ9q7SNJEr+aEZ3UAdVU8\n9lfFKef+qsavUbWEuipeqc8FSVJ8NMNhiv7Akgr7q3qFmipeSTXl7gsVfR1Ckt41szMUfS3i50Vu\nl31VFWlfn8p1xMQ/JX2hqMNaHS/4+UNFnb3OBdm2kj6If/5M6/5VoEOKMS1U9OBJkuJDc1onL14t\nr/J7dWOrunxNDZR0tZkt0jdvSJ43sx9nsXJ3LxzvfEXd0s0L/m3q7lcoul9bm9nGBcsnTQk1X9GL\naqvQJqsZ0n9U8Lwwsw0UvTn7IPEaxXs1sP2sH68sUFdlrqu4A3yOu3d2906Kvkc7X+u+MNdoEwU/\nz1d0IqDCumrh7r+QtFjRXx06FSyfVFeLFX3HMnQod6q6KthOFnU1UNLJZrYofp3qqOgwxVMzWHeW\nqCv2VyF1cn9VC69RWaGuyl9XlQ5TtB94OuP1Nqb9VX1ATdVeTRWuP7PZThrTvqpAqtensjQm3H2Z\nohPQXG9mw8ysZfx9mx6KvvOVdL2vFB0idHF8nc6Kvh82JV7kZUl9zWxbM9tM0lkphvVnSQeb2T5m\n1lzShcr29r8iaTcz2zV+Ip1f5fLFir6fk5Wuig6n6aHoOz9S9FeT+6Wvp9D5Q0bbuk3SUDPbL/5O\n0UZmNsDMtooPUXpV0jgzax4fSnZQaCXuPl/R95d+Z2abm1mzgkPPFisqrJYJY5gq6Ydm1j8+bPA0\nRd9nfC6D23e3pPZmdmR8+36s6Dta/8xg3ZmhrspfV2bWxqL5oc3Muku6UtFhhR5fPt7MHs9oc/dL\n2sXMRsS10MzMepnZTvEhdfdKusCiacy6K+Gwy/jxvVXStWbWIX4O7x3XyRJJHh8WGPJAPIYfm1lT\nMxuh6KRKWRwp1E/SrvrmdWqxohNZ1an5s6kr9lehldTV/VV1r1F1BXVVK3VV6WhJk6o+B9hfpWNm\nG5rZRvGvzQt+rhOoqVp5DzjAoq9GyMy2VXRuh/sKLmdflV7w9SlJ2aYLdffLFT3xT1d0xyyW9HtJ\nZyg6Y26SkxR1yN5T1F25Q9LEeJ2PKToZyKuSXlD0IlXseGYpOhTnDn1z1tLMDn109zck/VrR2Wvf\nUnSYZaE/SNrdzD42sz9Xt774Sfqpme2VsL0l8Xd+Fim6byWpwr/5TlYnRWfQrTGPvo82VNF3xyoU\nnVH2FH3z/DlC0ZllP1L0nargdwtjI+P//x2P+6R4G68rahDMsej7cu2qjGGWoif3DfEYDpD0Qy/i\ne4lF3JcfKupAn6XorLOnxuv+qLp11zbqqrx1pegwuYcV3VcPSPq9u08suDzLuvpE0v6KamKhor94\nXqLo5FaSdIKkLRQ9xjcrOkN1kpMlzVb0+H2k6D4zd18Rr/O5uK56VhlDhaITnJ2h6DDRkyUd7EVO\nN2dmb1nCX73dfWnla1T8OrVW0kfu/mkx665N1BX7qwR1bn+l6l+j6gzqquz7q8oPT30VnZSyKvZX\nBda3v4q9q+irve0lPSFplZnV5ESOmaOmyl5TPSU9a2YrFd1PL2rd82Sxr4pl8PoUvk4da7IjA3GX\n90VJu3nBSXIA1IyZvSqpX7FvhACsH/sroDzYXwHZYV9VO2hMAAAAAACA3JTtqxwAAAAAAADVoTEB\nAAAAAAByQ2MCAAAAAADkpkaNCTM7ID7L7TtmdmZWgwIAAAAAAI1DySe/NLMmiqYl2U/R1DDPSxoe\nT+0S1KZNG+/SpUtJ2wPK7YUXXvjQ3dvmPY60qCvUZfWxrqgp1GX1saYk6gp1G3UFZC9tXTWtwbZ6\nSXrH3d+TJDP7k6TBkhIbE126dNHMmTNrsEmgfMxsbt5jKAV1hbqsPtYVNYW6rD7WlERdoW6jroDs\npa2rmnyVY2tJ8wt+XxBnAAAAAAAARSn7yS/NbLSZzTSzmRUVFeXeHNAoUFdAtqgpIHvUFZA96goN\nVU0aEx9I6lTw+zZxtg53n+DuPd29Z9u29e6rW0CdRF0B2aKmgOxRV0D2qCs0VDVpTDwvaQcz+x8z\nay7pCEn3ZzMsAAAAAADQGJR88kt3X2Nmv5D0iKQmkia6+6zMRgYAAAAAABq8mszKIXefLml6RmMB\nAAAAAACNTNlPfgkAAAAAAJCExgQAAAAAAMgNjQkAAAAAAJAbGhMAAAAAACA3NCYAAAAAAEBuaEwA\nAAAAAIDc0JgAAAAAAAC5oTEBAAAAAAByQ2MCAAAAAADkhsYEAAAAAADIDY0JAAAAAACQGxoTAAAA\nAAAgNzQmAAAAAABAbmhMAAAAAACA3NCYAAAAAAAAuaExAQAAAAAActM07wEgG7vuumswf/3114P5\ncccdF8xvuummzMYEAAAAAEB1OGICAAAAAADkhsYEAAAAAADIDY0JAAAAAACQGxoTAAAAAAAgNzU6\n+aWZzZG0QtJXkta4e88sBgUAAAAAABqHLGblGODuH2awHhRh3LhxwfzNN99MtZ6bb745mB900EHB\nfMiQIanWD9RF++23XzB//PHHg3nXrl2D+bvvvpvZmAAA9cuHH4bf9ibtY5Leo/Xp0yfVek499dRg\n3rx582AOAPUJX+UAAAAAAAC5qWljwiU9amYvmNnoLAYEAAAAAAAaj5o2JvZx929LOlDSz82sb9UF\nzGy0mc00s5kVpPTtuAAAIABJREFUFRU13BwAiboCskZNAdmjroDsUVdoqGrUmHD3D+L/l0iaJqlX\nYJkJ7t7T3Xu2bdu2JpsDEKOugGxRU0D2qCsge9QVGqqSGxNmtqmZtaz8WdL3Jb2e1cAAAAAAAEDD\nV5NZOdpLmmZmleu5w90fzmRUSLR48eJgvmbNmlTradOmTTDfeeedU48JqGvOOeecYP7EE0+kWs82\n22yTxXCARufcc88N5rvsskswP+GEE4L5Cy+8EMyTZswBakPS4fOvvPJKqvX87W9/C+ZPPvlkMP/4\n44+D+RVXXJFqu0BtuPvuu4N50v5hhx12COZbbLFFMB8xYkQwb9KkSTDv2LFjMO/WrVswL7fnnnsu\nmM+aNSuYJ+0/e/fundmY8lZyY8Ld35O0e4ZjAQAAAAAAjQzThQIAAAAAgNzQmAAAAAAAALmhMQEA\nAAAAAHJDYwIAAAAAAOSmJrNyoIwmT54czCdOnJjJ+n/wgx8E85122imT9QO14ZNPPgnmSbNvuHsw\nb9myZTA///zzSxsY0Eg8+uijwTxploCNN944mC9btiyzMQHltv322wfzN954I5hfdtllqdZ/6623\nBvOkWT9WrlwZzDfZZJNU2wWylPRZ4/rrrw/m999/fzBv1apVMJ83b14wnzFjRjBv0aJFMN98882D\neTzzZI1tt912wXzRokXB/M033wzmnTp1CuYvvvhiME+agbEu44gJAAAAAACQGxoTAAAAAAAgNzQm\nAAAAAABAbmhMAAAAAACA3NCYAAAAAAAAuWFWjpwlnXn13HPPDeZffvllqvX37t07mJ933nmp1gPU\nRUlnOn/22WdTrWf8+PHBfN999w3mkyZNCuavv/56ME+aoQCoL+bMmRPMR48eHcyT9j2tW7cO5rNm\nzQrmnTt3rn5wQC1r1qxZMP/Wt74VzG+55ZZU60+alePxxx8P5s8880ww32+//VJtF8hS8+bNg/kH\nH3yQaj0HHnhgMB8wYEAwT5qV44svvgjmS5cuDeYbbBD++/2aNWtSrf/zzz8P5sOGDQvmSTPIbb31\n1sF87dq1wbw+4ogJAAAAAACQGxoTAAAAAAAgNzQmAAAAAABAbmhMAAAAAACA3NCYAAAAAAAAuWFW\njlqSdKbW//3f/w3m8+bNS7V+Mwvmw4cPD+Zdu3ZNtX6gLvrPf/6Tavmzzz47mP/85z8P5qtWrQrm\nl1xySTB/++23g/lhhx0WzPv06RPMgbom6SznSWdXHzx4cDB/7LHHgnmLFi2CeZMmTYoYHdCwJO2T\nrr/++mB+xx13BHNm5UBt+Oqrr4L5DTfcEMyTZnlKcuedd6bKe/ToEcwnTJgQzPfcc89U43n33XeD\n+ahRo4L54sWLg/mll14azFu1apVqPA0JR0wAAAAAAIDc0JgAAAAAAAC5oTEBAAAAAAByQ2MCAAAA\nAADkptrGhJlNNLMlZvZ6QbalmT1mZm/H/29R3mECAAAAAICGqJhZOW6V9FtJkwuyMyU94e6XmtmZ\n8e9nZD+8+ifpzLR9+/YN5v/6178y2W7SmWB/+ctfBvO1a9cG82uvvTaYv/POO8F8zJgxwXzHHXcM\n5kApli9fHswfeeSRYN6yZctgfvTRRwfzpDP/J51R+q233grmG220UTDfZJNNgjlQ17z//vvB/PTT\nTw/mv/rVr4L5ZZddFsyPOOKIYN65c+ciRgc0Dqeeemowv/XWW4N50r5w/vz5wbxTp04ljQsImTRp\nUjBPeh6vXr06mDdr1iyY77LLLsE86TPIj370o2Ce1Xux7bbbLpgPGTIkmJ9xRvgj8l133RXMf/rT\nn5Y2sAag2iMm3P0pSR9ViQdLqnwWTpIUfiQAAAAAAADWo9RzTLR394Xxz4sktc9oPAAAAAAAoBGp\n8ckv3d0ledLlZjbazGaa2cyKioqabg6AqCsga9QUkD3qCsgedYWGqtTGxGIz6yhJ8f9LkhZ09wnu\n3tPde7Zt27bEzQEoRF0B2aKmgOxRV0D2qCs0VKU2Ju6XVHkWuaMl3ZfNcAAAAAAAQGNS7awcZvZH\nSf0ltTGzBZLOl3SppKlm9lNJcyUdXs5B1kVffPFFMB8xYkQwz2r2jcMPD9/V11xzTar1XHnllcE8\n6cyxSV566aVg/s9//jPVeoD1uf3224P5okWLgvmgQYOC+Q477JBqux988EGq5Vu3bh3Md9ttt1Tr\nAcotaWamCy+8MJi3aNEimJ988smZjQlApEuXLsH8qKOOCuY33nhjMF+5cmVWQwI0ffr0YD5u3Lhg\nnvRZKUnSbE5Js3vUNQcffHAwP//884P5BRdcEMwHDBgQzLt27VrawOqRahsT7j484aKBGY8FAAAA\nAAA0MjU++SUAAAAAAECpaEwAAAAAAIDc0JgAAAAAAAC5oTEBAAAAAAByU+3JLxu7VatWBfOkM6ze\nc889mWy3T58+wfz6668P5ltuuWUwf+yxx4L5ueeeW9rAqnD3TNYDrM/bb7+davl99903k+3+9a9/\nzWQ9QF0za9asYH7rrbcG8wkTJgTzDh06pNrus88+G8w7d+6caj1AY9StW7e8h4BGrG3btsF8zz33\nDObbbLNNMB86dGgwHz16dGkDqyOS6nOTTTYJ5vPnzw/mb7zxRjBvDLNycMQEAAAAAADIDY0JAAAA\nAACQGxoTAAAAAAAgNzQmAAAAAABAbmhMAAAAAACA3DArRzWOP/74YD558uRM1t+qVatgfvXVVwfz\n1q1bB/P3338/mJ900knB/MsvvyxidNXr169fJusBsrTrrrumWr6ioiKYL1y4MNV6DjrooFTLA+W2\ndu3aYD5+/Phg/u1vfzuYH3vssZmMZ8mSJcE8aWYpAEDdkDT7xp///OdgnrT/adKkSWZjaog+/PDD\nvIeQG46YAAAAAAAAuaExAQAAAAAAckNjAgAAAAAA5IbGBAAAAAAAyA2NCQAAAAAAkBtm5Yj95S9/\nCeYPP/xwJutv0aJFMJ82bVow32uvvYJ50mwaZ511VjB/6623ihhd6ZLutz322COYH3roocG8efPm\nmY0JDc+yZctSLd+tW7dUy0+ZMiWYL168ONV6Nt1001TLA+U2Z86cYD516tRgnrTPK/dZ1L/73e+m\nWn7NmjXBvGlT3tYAQG0ys2DO7Buleeihh4L5McccU7sDyQFHTAAAAAAAgNzQmAAAAAAAALmhMQEA\nAAAAAHJDYwIAAAAAAOSm2saEmU00syVm9npBNs7MPjCzl+N/PyjvMAEAAAAAQENUzOmrb5X0W0mT\nq+TXuPuVmY8oJyeccEIwX7JkSar1JJ2V/9577w3m++67b6r1X3XVVcH8zjvvTLWerMyePTuYDx8+\nPJgfd9xxwfymm27KbEyov1auXBnMp0+fXtbt3nXXXWVdP5CXpNrp1KlTMO/fv38ZR5MsacapCy+8\nMJj37t07mO+///6ZjQmoa8aOHRvM3T1VDgB1UbVHTLj7U5I+qoWxAAAAAACARqYm55j4hZm9Gn/V\nY4vMRgQAAAAAABqNUhsTN0jaTlIPSQslhb9fIMnMRpvZTDObWVFRUeLmABSiroBsUVNA9qgrIHvU\nFRqqkhoT7r7Y3b9y97WSbpLUaz3LTnD3nu7es23btqWOE0AB6grIFjUFZI+6ArJHXaGhKqkxYWYd\nC34dKun1pGUBAAAAAACSVDsrh5n9UVJ/SW3MbIGk8yX1N7MeklzSHEk/K+MYM/Xqq68G86VLl2ay\n/t/97nfBvG/fvsF89erVwfzhhx8O5hdddFFpA6sjHn300byHgDps3rx5wXz58uXBfIcddgjm7du3\nD+ZJhzy+//77RYyuejvvvHMm6wGykjTz00knnRTM+/TpE8xHjhwZzHfcccdgPmPGjGCetM8bMWJE\nMO/VK3xAZtLsBEBDZmaZ5ADqrjlz5gTzNWvWBPOmTYuZZLN+qPaWuHto3sebyzAWAAAAAADQyNRk\nVg4AAAAAAIAaoTEBAAAAAAByQ2MCAAAAAADkhsYEAAAAAADITcM5jWeRNtgg3IvJ6szFxxxzTKq8\noWrVqlUwv/DCC2t5JKhPtt5662DeokWLYP72228H8/nz5wfzP/3pT8F80aJFRYzuG82aNQvmPXv2\nTLUeoNySZop59tlng/kFF1wQzNPOCJV09vCk/PTTTw/mJ598cjBP2pcDDcFrr70WzL/88stgvv32\n2wfzpPdiAOqu3XbbLZg3pNk3krBnBwAAAAAAuaExAQAAAAAAckNjAgAAAAAA5IbGBAAAAAAAyA2N\nCQAAAAAAkJuGf3rPKrp37x7Mk85c/uKLL5ZzOPXGgAEDgnm7du2C+WmnnRbMv/Od72Q2JjQ8LVu2\nDOZJdTtjxoxgPmTIkGD+1ltvlTawKkaNGhXM99hjj0zWD2Qlacap3r17B/Pp06dnst2k2tx3332D\nea9evYI5s2+gMRo4cGAw/+KLL4L53nvvHcw7duyY2ZgArN/EiROD+YoVK1KtZ/DgwVkMp15ijw8A\nAAAAAHJDYwIAAAAAAOSGxgQAAAAAAMgNjQkAAAAAAJAbGhMAAAAAACA3jW5WjiTTpk0L5iNHjgzm\nf//738s5nMx06NAhmPfv3z+YDxs2LJgfeuihwTzpjO9Alnr06BHMk878n3b2jY022iiYf/7558E8\nabae1atXB/NmzZqlGg9Q3z3xxBPBPGnmnT333LOcwwHqlYqKimDOey4gf0mz44wbNy6YJ703bNWq\nVTBvzDMYcsQEAAAAAADIDY0JAAAAAACQGxoTAAAAAAAgNzQmAAAAAABAbqptTJhZJzObYWZvmNks\nM/tlnG9pZo+Z2dvx/1uUf7gAAAAAAKAhKWZWjjWSTnH3F82spaQXzOwxScdIesLdLzWzMyWdKemM\n8g21vLbddttgnnRm8aSz/g8ePDiYv/fee6UNrEhnnnlmMP/Vr34VzNu2bVvO4QCZOvHEE4P5smXL\ngvn7778fzA877LBgvmDBgmB+2WWXBfNXX301mL/yyivBvGfPnsEcaKhWrlwZzDfYIPz3kKSZcQBU\n79hjj817CECj8dBDDwXz+fPnp1rPmDFjgnnHjh1Tj6mhqPaICXdf6O4vxj+vkDRb0taSBkuaFC82\nSdKQcg0SAAAAAAA0TKnOMWFmXSTtIek5Se3dfWF80SJJ7TMdGQAAAAAAaPCKbkyYWQtJd0sa4+7L\nCy9zd5fkCdcbbWYzzWxmRUVFjQYLIEJdAdmipoDsUVdA9qgrNFRFNSbMrJmipsTt7n5PHC82s47x\n5R0lLQld190nuHtPd+/JeQ2AbFBXQLaoKSB71BWQPeoKDVUxs3KYpJslzXb3qwsuul/S0fHPR0u6\nL/vhAQAAAACAhqyYWTn2ljRK0mtm9nKcjZV0qaSpZvZTSXMlHV6eIearWbNmwbx79+7BvGvXrsE8\nq1k5kmb9OO+884L5xhtvnMl2gTxtv/32wXzixImZrH/gwIGplk+axYfZN4BI+/acdgqoLe+8804w\n/973vlfLI0FjtHr16mA+bdq0YD5s2LBgnjRrU16Sxn/UUUelWs/w4cODedKMio1ZtY0Jd39akiVc\nnO7dPAAAAAAAQIG61ZoCAAAAAACNCo0JAAAAAACQGxoTAAAAAAAgNzQmAAAAAABAboqZlQMBn3/+\neTBftGhRJutPOuv/8ccfH8yZfQMo3ZIlS1Itz5nOgfXr169fML/44ouD+UcffRTMt9xyy8zGBNQX\nBxxwQDB/5JFHgvn+++9fzuEA67V27dpgftpppwXzQYMGBfO8Xu/vu+++YD5ixIhgnvQZMMlvf/vb\nYM5nt//GERMAAAAAACA3NCYAAAAAAEBuaEwAAAAAAIDc0JgAAAAAAAC5oTEBAAAAAAByw6wcJdpo\no42C+RlnnBHMx44dG8z32WefYD5u3LhgvuOOO1Y/OABBy5YtC+affPJJqvX06tUri+EADVafPn2C\neZMmTYL5rFmzgjkz4KAxevLJJ/MeAlC0DTfcMJjfdtttwbxLly7BfOjQocE8aUbCJJ999lkwv/zy\ny4P5jBkzgvmaNWuC+TbbbBPMb7jhhmC+xRZbBHP8N46YAAAAAAAAuaExAQAAAAAAckNjAgAAAAAA\n5IbGBAAAAAAAyA2NCQAAAAAAkBtm5cjYyJEjU+UAas+KFStS5cOGDQvmRx55ZGZjAhqT/fffP5in\nnRkHaMjOO++8YH722WfX8kiA0vXt2zeY33TTTcH8kksuCeYDBw4M5qtWrSptYFUkzbQ4fPjwYH7l\nlVcG83bt2mUynsaMIyYAAAAAAEBuaEwAAAAAAIDc0JgAAAAAAAC5oTEBAAAAAAByU21jwsw6mdkM\nM3vDzGaZ2S/jfJyZfWBmL8f/flD+4QIAAAAAgIakmFk51kg6xd1fNLOWkl4ws8fiy65x9/CpSQGg\njunUqVMw//jjj2t5JEDjdMwxxwTzRx99NJgffPDBZRwNUDedddZZqXKgPvnxj3+cKn/llVeC+Zgx\nY4J5ly5dUo3nW9/6VjA/44wzUq0HNVdtY8LdF0paGP+8wsxmS9q63AMDAAAAAAANX6pzTJhZF0l7\nSHoujn5hZq+a2UQz2yLjsQEAAAAAgAau6MaEmbWQdLekMe6+XNINkraT1EPRERVXJVxvtJnNNLOZ\nFRUVGQwZAHUFZIuaArJHXQHZo67QUBXVmDCzZoqaEre7+z2S5O6L3f0rd18r6SZJvULXdfcJ7t7T\n3Xu2bds2q3EDjRp1BWSLmgKyR10B2aOu0FAVMyuHSbpZ0mx3v7og71iw2FBJr2c/PAAAAAAA0JAV\nMyvH3pJGSXrNzF6Os7GShptZD0kuaY6kn5VlhAAAoEE44IADUuUAgMZt9913D+YzZsyo5ZGg3IqZ\nleNpSRa4aHr2wwEAAAAAAI1Jqlk5AAAAAAAAskRjAgAAAAAA5IbGBAAAAAAAyA2NCQAAAAAAkBsa\nEwAAAAAAIDc0JgAAAAAAQG5oTAAAAAAAgNzQmAAAAAAAALmhMQEAAAAAAHJDYwIAAAAAAOTG3L32\nNma2QtJbtbbB/LWR9GHeg6hF9f32dnb3tnkPIi3qqsGr77e33tUVNdXg1ffbW+9qSqKuGoH6fnup\nq/qhvj/P0qrvtzdVXTUt50gC3nL3nrW8zdyY2UxuL2oBddWANbbbW0dQUw1YY7u9dQh11YA1tttb\nh1BXDVhju718lQMAAAAAAOSGxgQAAAAAAMhNbTcmJtTy9vLG7UVtaGz3O7cX5dbY7nNuL2pDY7vf\nub2oDY3tfuf2NmC1evJLAAAAAACAQnyVAwAAAAAA5IbGBAAAAAAAyA2NCQAAAAAAkBsaEwAAAAAA\nIDc0JgAAAAAAQG5oTAAAAAAAgNzQmAAAAAAAALmhMQEAAAAAAHJDYwIAAAAAAOSGxgQAAAAAAMgN\njQkAAAAAAJAbGhMAAAAAACA3NCYAAAAAAEBuaEwAAAAAAIDc0JgAAAAAAAC5oTEBAAAAAAByQ2MC\nAAAAAADkhsYEAAAAAADIDY0JAAAAAACQGxoTAAAAAAAgNzQmAAAAAABAbmhMAAAAAACA3DTqxoSZ\nzTGzQTluf4GZ9c9r++ViZseZ2ZPxz03M7FMz27aE9RxtZg9lPkCUFXVVHmY2yMzmFPz+lpl9r4T1\n9DezWZkODmVHXZUH+6vGjboqDzMbb2a3xj93NbNPS1zPuWZ2Y6aDQ1lRU+XRWGqqrI0JMzvCzJ4z\ns8/MbEn884lmZuXcbk2Z2UPxm5NPzWy1mX1Z8HtJD6aZTTGzcRmO8dyCMX1qZqvM7Csz26KI625v\nZl5w3ffN7LSsxlbI3b9y9xbuPq+YMVW57iR3P7Ac46qy7Y3N7G4zmxvfL/uUe5s1QV2ts85M6ype\n55h4x7rczP5lZt8t8npN4+fPZ/FtWmBmV5hZWV5n3X0nd/97kWPqUnC9J919l3KMqcq2dzazv5hZ\nhZl9FD/+O5R7u6WirtZZZ9b7KzOz88xsXlxXd5hZiyKvy/4qeRwXxvdN/9rcbhrU1TrrzLquBpnZ\n2irvBY8s4borzOxNMzs6q7EVcvf33L3aercqzff4uhe5+/HlGFdg26+b2TIz+zB+T9ix3NstBTW1\nzjozfw9YsO7JVd8/VbM8NbXutkva75etMWFmp0i6TtIVkjpIai/peEl7S2qecJ0m5RpPGu5+YPzm\npIWk2yVdXvl76ME0s6Y5jPGigjG1kHSVpCfc/eMU66i87ihJF1qgw5nHbcuBS3pK0ghJFTmPZb2o\nq/Iys70lXSRpqKTNJd0m6Z6UO/xd4tv4fUlHSzo2sJ3GUFebSbpH0k6KnqcvS5qW64gSUFdld6yk\nIyTtJWlrSa0U3d9FY3+1LjPbUdIQSUvyHksS6qpWzCt8L+jut6e9rqJ6PFvSzWa2U9WFGkldvS5p\nP3ffXNFr1BxJv8t1RAHUVO2Im71dSrgqNfWN0vb77p75P0VvSD+TdFg1y90q6QZJ0+PlB8XXnazo\nA+JcSedI2iBefpykKQXX76LoQ2XT+PcnFX2oeEbSCkmPSmpTsPyoeJ1LFT1h5kgaVMQYx1fJBsXX\nHStpkaRbJB0n6cmCZZrGY+si6URJqyV9KelTSdPiZRZI+pWk1yR9IumPkjYs4f62+HYdWeTy20cP\n/TrZS5LGFIz7REnvSHonvrybpMclfSTpzcLHVlJbSQ9IWi7pWUkXV94XhfdD/Psmkq6RNC++zU9J\n2lDSf+LlPo3/7Rm4T/eRNDO+3r8k9S647GlJF0j6R/zYPyxpyxLuy0WS9ilHXVBXdb+uJB0p6R9V\n7nOX1LaI667zXI+zaZKuLRjXafG4voizbeJlKiS9L+nnBdfdRFFj5GNJsySdIWlOweULJPUv2Pa5\nkt5VVIczJW0V14PHz4NPJR1WeT8XrGcXSX+TtCwe20EFl02R9H+SHoof+39K+p8Sn7/t4rFslnct\nUVe1Xlf3Sjq54Pe+klZK2qiI67K/Ct8vjylqfn79OlCX/om6Wuf5pPLU1Tqv5Skfn/+6rqJ9zRDF\nNSfpJ/Fz/6/x5XvHNbNMUaO5b8F1u0r6e3yfPxI/preGalhS6/g+XRhv8+74MV8laa2+qat2ksZX\nrie+7lBF+8Nlkv4qaaeCy7J6T72Rog/+r+ZdR9RU7X+2ktRM0iuSdleV93TUVPn3++U6YmIvRTvv\n+4pYdoSiNwYtFe2sf6PozuwqqZ+koxQ9kMUaES/fTlH38FRJMrNuih7UUYresLdW9KGgVNtIaiFp\nW0XFkcjdr5d0p6Rfe9QZHFpw8eGS9lN0e78Tj6/yu67LzKxPEWMZoOivu6n/GhkfavM9STsrerNX\n6YeK3mztGh9685iiF7V2ij68TSjoAt6gqHA6SBqtwF+IC1wjaTdJvSVtqegFaK2iJ6z8m+7p81XG\n2UbSg4qODGmt6Hky3db96soIRX+hbi9pU0XFVHn9WWZ2eDH3SR1GXRUoU109KGkjM9sz/ivDsZJe\ncPfUR9KY2S6KdjqFdXWEpAMlbW7RVzwekPS8om7yfpJOM7OB8bIXSuoU34YfKHpuJzlN0jBJByh6\nLThO0ueK60rxURzufneVMTaPx/Cgog9sJ0u608y2L1hshKKmx5aKdqgXFVz/ITM7tdo7I9JX0gJ3\n/6TI5WsLdVWgjPsrq/LzxpK2S3Mj2F99fflwScvd/dH1jD1v1FWBMtbVVma22MzeM7OrzGyTtDfC\nzDYws2HxbXmt4KK+kr4l6SAz6yTpfknnK6qFMxUdTdg6XvZORR+w2ki6pPI2JLhD0ePSTdFjdF28\nXzhE6x4Bss7RQGa2s6Jm/UmK9lePS7rfzJoVLFbyfWlm/2NmyxR9ePqlpMvXcxvyQE0VKGNNnaro\nuVXyubioqW82UeXnavf75WpMtJH0obuv+Xo0Zv+Ib8AqM+tbsOx97v6Mu69V1Pk6QtJZ7r7C3eco\n2rGv78Go6hZ3/7e7r5I0VVKPOB8m6QF3f8rdv1D0RnttybdQWiNpnLt/GW+rVNe6+yJ3X6roA0IP\n6evvum7u7s8WsY6jJd3l7ivTbDh+Af5I0gRJp7j73wou/rW7fxzftsGS/u3uk919jbu/oKgTNix+\n8g6RdK67r3T3VxU9yUPbayLpGEn/z90XxrfxaXdfXcRwD5E0y93/GI/hNknvSTqoYJmb3f3t+H64\nS9889nL3Xdx9alF3TN1FXRWv1LparqjB9w9JX0g6S9GHlzRejWvrPkU77MkFl13n7gvi27aXpFbu\n/uv49r4j6WZFj5UU7QzGx3U4V9Jv17PN4ySNjZ//a939ZXf/qIixVh7+eYW7r3b3xxUdHXFEwTJ/\ndveZcZ3ernXr6kB3v7K6jVh0MsH/U8GHrzqEuipeqXX1sKTRZtbZzDaXdHqcF/0hiv3V1+Nqpag5\neHIR48gTdVW8UutqlqK/6nZU9MGhj6K/9Bdr27iuPlT0l+4j3f3dgsvPj+tklaIPsve7+yPxPuZh\nRX9VPsDMusbjON/dv3D3JxX9tf6/xB/GBko6Ia7Z1e7+VJHjPSIew1/jOrxU0Yft3gXLlPye2t3f\n9+irHG0lnSfprSLHVVuoqeKV9Dwws86KmtXjStwuNfWNkvb75fqOy1JJbcysaWUBuft3pehsqVq3\nITK/4Oc2ig6hmVuQzVX018RiLSr4eaWibpUUdfK+3pa7f2ZmS1Ost6rF7v5lDa5fqep4t0xz5fiv\nQ4cp+itsKvELcJLCx6WzpL3jYqvUVNFhQ+0lNamy/FxJvQLrbK/oQ9C7gcuqs5XWfV5UbqfwuZH0\n2DcU1FXxSq2r0ZJGKuo6v6foCITpZra7uy8uch27xTv+kKp1tW2Vumqi6LBJKXqzWbWuknRS6XU1\nzz06zq5gO5nVlZm1U3To53XuflcJYyw36qp4pdbVTYr+EvaUovvzGkVHAS0odsPsr752kaSJXs0J\nOusA6qp4JdWVuy9UdOi2JL1rZmcoOoT750Vud567d1nP5VXrariZFf5VupmiDx9bSVrq6/5xbK6i\nD/hVdVKVtZv7AAAgAElEQVT04bqUI+fWqSt3Xxs/l9ZXV6neU8frXWpmUyQ9b2Zbxx/u6wJqqnil\nPg/+T1EzYIWVdh4IauobJe33y3XExD8V/bVxcBHLFr4h/lBRZ69zQbatpA/inz/Tup2WDinGtFDR\ngydJig93a528eLW8yu/Vja3q8lk5TNJiRYdqZalwvPMVnVhz84J/Ldz9F/G216rgvlX0mIUsVvRd\nsNBhPNXdP//Rus+Lyu18EFi2oaKuyl9XPRR1j9+Ou8EPKrr/9spo/VXr6u0qddXS3Q+JL1+k4uqq\ncl2l1lUns3VO7plZXcWHJD6u6KiLy7JYZxlQV2Wuq7iWznH3zu7eSdF5H+Zr3Tc8NdpEwc8NfX81\nUNLJZrbIzBYpamDek+IrVbWFuqq994GF689sZoYqDev5iv5qXlhXm7r7FYru19ZmtnHB8kl1NV/R\nh+tWoU1WM6R16sqir0Nuo/K8D2yq6PGrS3/goqbKX1MDJV0dv7ZWfoB+3sx+nMXKG1NNlbrfL9c0\ndssUndjpejMbZmYt4+/b9FD0Xcqk632l6BChi+PrdFZ06O+UeJGXJfU1s23NbDNFh1kX68+SDjaz\nfSz6XvWFyvb2vyJpNzPbNX4inV/l8sWKvp+TtaMlTaryZK+c7/bxjLZxv6RdzGyEmTWL//Uys53i\nQ3/ulXSBRdNudlfC4WHx43urpGvNrEP8/aS948Nrl0jy+PClkAfiMfzYoikQRyg6+cuDWdxAM9vQ\nzDaKf21e8HOdQV3VSl09r+j2dLHI/oo+mMySJDM7zszeyWhb/5T0pZmdYmYbxfWwq5l9J758qqSx\nZra5RV+F+MV61vUHSePNbLt43D3MbMv4sV+q5PvoH4oOnTwlrut9FXW076zpjYufS48qOsnTOTVd\nX7lQV+WvKzNrY9G86xbvI65UdLiux5ezvypeP0m7Kmqi9lD0WB0nqU7NS09d1UpdDbDoMO7Kr8td\nooLzD1g0leIfMtrcbZKGmtl+cS1sFG9/q/hQ9VcljTOz5hZ9peCg0Ercfb6iZvXv4n1bM/vmKwiL\nFX3AapkwhqmSfmhm/eM6PE3R+WKeq+mNM7PDzGyH+DWqnaKvOjzv7struu6sUFO18h6wq755ba18\nL/YDRfsVaiqF6vb7Sco2Xai7X67oiX+6ojtmsaTfKzqz/D/Wc9WT/j979x6v1Zz3f/z9UZGYxLST\nicodo7pFiBmHwiCHmZGaud0YiUERjYxhFA0zhhpzE3NPN0JIISEatwoNld8Y7HLsNNFdOXTYnUY5\nJX1/f6zV2OWz2tfae1177cPr+Xj0aO/3vvZan+vw2de1P3td66toQrZQ0VEAD0kaFW/zOUUvmN+S\nNFPRk3+h9cxWdHjbQ/r6rKUFH0ZawPbnSLpJ0WHY8xUdulLePZIONLM1ZvZYRduLH6TrzSzxL7Xx\nE1E3bfke9s32UnQG3SqLDw86UdEh7ksVTbuGKjoJjyRdLGlXRffxvYrOpJvkcklzFd1/qxXdZhZC\nWBdv8xWL3i/XZasayhSd4OzXin7RulzSj0KBy6Oa2Xzb9sTzPUVnr91d0lRJn5lZVU7gUxT0VdH7\n6j5FS1xOV3QG4uGSzg8hLIi/nmVfbVT0hHeYojNRr1R0X26eel+n6DZdpOi8D16fb/ZHRb9wTVV0\nnoyRis4svnk7D8V91WurGr5Q9H74HvH+/yTprHLXd5vM7Fkzuyrhyz+VdLCkC+zrtcrXm9l3Ctl2\ndaKvit5XJYoOT/1E0e1wVwhhVLmv83xVzraer0IIq0L0ft9lIYRlio4AWR1CWF/ItqsTfVX0vuoi\n6e9m9qmi22mWtjz3SJZ9tUjR2fuHKFrZYYmkK/T17xFnKDpn0WpF7613z90SOzv+/x+KHhMD4n28\no+itKIvivmqxVQ2zFf0x7o64hpMknRoKOO9LAbflXooG6esV/TK8QdFzWI1CTxW3p0IIK8r9bN38\n9t2y8PX5LuipWAbP+/52KxhcoJYys7ckHV3oCyEAFTOzqYpOMPSPvGsB6gqer4BsWXTU5yxF5zza\nWNHlAWwbPVU9GEwAAAAAAIDcFO2tHAAAAAAAABVhMAEAAAAAAHLDYAIAAAAAAOSmYVW+2cxOknS7\npAaS7gkhDNvW5Zs3bx7atm1blV0CRTNz5syVIYSSvOtIi75CTVYb+4qeQk1WG3tKoq9Qs9FXQPbS\n9lWlBxNm1kDSCEknKFoa5jUzmxgv7eJq27atSktLK7tLoKjMbHHeNVQGfYWarDb2FT2Fmqw29pRE\nX6Fmo6+A7KXtq6q8leMwSe+GEBaGEDZIekRSjypsDwAAAAAA1DNVGUy0kvR+uc8/iLMtmFlfMys1\ns9KysrIq7A7AZvQVkC16CsgefQVkj75CXVX0k1+GEEaGELqEELqUlNS6t24BNRJ9BWSLngKyR18B\n2aOvUFdVZTDxoaS9yn2+Z5wBAAAAAAAUpCqDidck7Wtme5vZ9pLOkDQxm7IAAAAAAEB9UOlVOUII\nG83sUklTFC0XOiqEMDuzygAAAAAAQJ1X6cGEJIUQnpH0TEa1AAAAAACAeqboJ78EAAAAAABIwmAC\nAAAAAADkhsEEAAAAAADIDYMJAAAAAACQGwYTAAAAAAAgNwwmAAAAAABAbhhMAAAAAACA3DCYAAAA\nAAAAuWEwAQAAAAAAcsNgAgAAAAAA5IbBBAAAAAAAyA2DCQAAAAAAkBsGEwAAAAAAIDcMJgAAAAAA\nQG4YTAAAAAAAgNw0zLsAAKisyZMnu/nQoUPdfO7cuW7eq1cvN+/evXuqywMAUNcMHz7czb/88stU\n21m2bJmbr1q1ys0feOCBVNsHULtxxAQAAAAAAMgNgwkAAAAAAJAbBhMAAAAAACA3DCYAAAAAAEBu\nGEwAAAAAAIDcVGlVDjNbJGmdpK8kbQwhdMmiKAD1U1lZmZufc845bj5lyhQ3NzM3DyG4+d13351q\n+926dXPz5s2buzlQ02zatMnNJ06c6OY9e/Z0865du7r5008/7eZNmzYtoDqgfhs3bpybf/LJJ6m2\nc+ihh7r5tdde6+YvvfSSm69evTrVftM6+eSTi7p9ALVDFsuFHhtCWJnBdgAAAAAAQD3DWzkAAAAA\nAEBuqjqYCJKeNbOZZtbXu4CZ9TWzUjMrTTpMG0A69BWQLXoKyB59BWSPvkJdVdXBxFEhhIMlnSzp\nEjP7xhuvQwgjQwhdQghdSkpKqrg7ABJ9BWSNngKyR18B2aOvUFdVaTARQvgw/n+FpAmSDsuiKAAA\nAAAAUD9U+uSXZraTpO1CCOvij7tL+l1mldVSixcvdvOks/6vXOmfN7R9+/ZunnRm9KTtnH322W7e\nr18/Nx84cKCbA5WRth9uvPFGN09aZePEE0908wcffNDNk1bNGDlypJsn9cmQIUPc/I477nBzoKaZ\nM2eOm/fq1cvNk3ow6Sz+Sat7JD0nAfVRp06d3HzevHluvnHjxlTbT/pretrD/0866SQ3b9gw3a8R\nP//5z9382GOPTbUdYFs+/vhjN0967TZ37txUlz/iiCPcvEGDBgVUh22pyqocu0uaEL9YaSjpoRDC\n5EyqAgAAAAAA9UKlBxMhhIWSDsywFgAAAAAAUM+wXCgAAAAAAMgNgwkAAAAAAJAbBhMAAAAAACA3\nVTn5JRyHHeavmJq0akYIwc2TzoA+dOjQTLY/f/58NweydM4557h50pn8jz76aDcfPHiwm3fv3r1y\nhW0laSWCiy66KJPtAzVN0qoZScaPH+/mSat7nHbaaalrAuqbXXbZxc0POeQQN//ud7/r5nvvvbeb\n/+536RbLS3rOHjVqlJuzCgHy9M9//tPNb7rpJjf/05/+lGr7zz33nJvff//9bt6nT59U209aDeTd\nd9918zZt2rj5AQcckGq/NRlHTAAAAAAAgNwwmAAAAAAAALlhMAEAAAAAAHLDYAIAAAAAAOSGwQQA\nAAAAAMgNq3JkbMWKFW6edHb/gw46KNX2+/bt6+a//OUv3Xz48OFufuGFF6baLyBJixcvdvOk1Wh2\n3HFHN3/sscfcvGfPnpUrrIqaN2/u5kmr2kybNq2Y5QCZ+fjjj9086ezkrVu3dvMjjzzSzX/yk59U\nrjAAiStUJfn000/d/Pjjj8+iHHXu3NnNWX0Defr888/dPGlFtb/+9a/FLEe///3v3TxpVY4333zT\nzX/wgx+4+erVq938W9/6lpuXlZW5+Q477ODmNRlHTAAAAAAAgNwwmAAAAAAAALlhMAEAAAAAAHLD\nYAIAAAAAAOSGwQQAAAAAAMgNq3JkzMxSXT5plY2stGjRws2TViEAtuXyyy9385KSEjd/8cUX3bym\nPf6eeOIJN0/q5+22Y6aL2uH5559386QVpH73u9+5ecuWLTOrCcC2vfrqq25+/fXXu/nLL7+cavtJ\nz8FJz/FAdUhaReq0005z8xdeeCGT/SatINeuXTs3P/bYY9383XffdfOkVXOSVt9Ism7dOjcfMWKE\nmyet2FiT8eoaAAAAAADkhsEEAAAAAADIDYMJAAAAAACQGwYTAAAAAAAgNwwmAAAAAABAbipclcPM\nRkn6kaQVIYT942w3SeMktZW0SNLpIYQ1xSuz9ujataubJ50BPSszZsxw8912283Na9qqCKgdXnrp\nJTefPHmym9eWx9mECRPcvEmTJm5+ww03FLMcIDfLly/PuwSg3vjb3/7m5jfffLObT5o0KdX2W7Vq\n5eYffPBBqu0A1eGSSy5x86xW32jfvr2bDxkyxM3POussNy8tLXXz008/3c1XrlxZQHWVt3DhwqJu\nvzoVcsTE/ZJO2iq7WtLUEMK+kqbGnwMAAAAAAKRS4WAihDBd0tYLrfaQ9ED88QOS/AVmAQAAAAAA\ntqGy55jYPYSwNP54maTdky5oZn3NrNTMSsvKyiq5OwDl0VdAtugpIHv0FZA9+gp1VZVPfhlCCJLC\nNr4+MoTQJYTQpaSkpKq7AyD6CsgaPQVkj74Cskdfoa6q7GBiuZntIUnx/8U9syMAAAAAAKiTKlyV\nI8FESX0kDYv/fyqzimq5wYMHu/kpp5zi5nPnznXzDh06ZFLP6tVbnx4kknSG2NatW2eyX9RNSWci\nri2rbyQd8pi02khSH/bs2TOzmoBiOuSQQ9y8WbNmbv7888+7+fr169185513rlxhAHTccce5+eef\nf57J9ocNG5bJdoDK+Oqrr9w86XeiadOmZbLfAw44wM2fffZZN096PhwzZoyb9+/f383XrVtXQHWV\n16hRIzdPuj1rowqPmDCzhyW9LGk/M/vAzM5XNJA4wcwWSDo+/hwAAAAAACCVCo+YCCGcmfAlf8wL\nAAAAAABQoCqf/BIAAAAAAKCyGEwAAAAAAIDcMJgAAAAAAAC5qeyqHEiQtDpBCMHNZ8yY4eZZrcqx\nYoW/kiurcqAyavvjo1+/fm6+ePFiN2/fvn0xywGKrk2bNm7euXNnN3/xxRfd/I033nDzo446qlJ1\nVdXTTz/t5iNGjHDzu+++28333HPPzGoCpk+f7uZnnHGGm2e1+kaSAQMGuPlVV13l5ieccIKb33PP\nPW6etEoAIEljx45186TVMdJKen5L2v6SJUvc/IgjjnDzhQsXVq6wKkp67Xnvvfe6eVL9tRFHTAAA\nAAAAgNwwmAAAAAAAALlhMAEAAAAAAHLDYAIAAAAAAOSGwQQAAAAAAMgNq3JUEzPLZDtlZWVunrTK\nRlb7BfI0d+5cN3/88cfd/KmnnnLzmTNnunlSn8ybN8/NDz30UDdPWpVn8ODBbt61a1c3B4rt0Ucf\ndfMWLVq4+V133eXmSWcD3267bP7usWDBAje/7LLL3HzTpk1uXlJSkkk9qF/Wrl3r5pdeeqmbP/PM\nM26+Zs2azGpKI6n+pHz06NFuPmvWLDefNGmSm7PaDSTpuuuuK+r2k167JfVn0mvDL7/8MrOa0thx\nxx3dfNiwYW5el1bfSMIREwAAAAAAIDcMJgAAAAAAQG4YTAAAAAAAgNwwmAAAAAAAALlhMAEAAAAA\nAHLDqhwZO+SQQ9x8/Pjxbt6hQ4dU21+yZImbL1682M2TVglIyoHqMH36dDe/7bbb3PzJJ5908yZN\nmrh50pmaQwhunnTG/saNG7t50uoeSdufMmWKmz/22GNu3qtXLzcHspJ0NvAkY8eOdfODDjrIzX/5\ny1+m2v6MGTPc/JxzznHzpOe8pN7cYYcdUtUDSMmP46R+SCvpuadVq1aZbP+HP/yhmyetspO0wts7\n77zj5hs2bKhcYUAGFi1alCqvaU466SQ379GjRzVXUnNwxAQAAAAAAMgNgwkAAAAAAJAbBhMAAAAA\nACA3DCYAAAAAAEBuGEwAAAAAAIDcVLgqh5mNkvQjSStCCPvH2fWSLpRUFl9scAjhmWIVWRcU+yz7\nSasQJJ1hOSlv3bp1ZjUBSTp27Ojm1157bao8aVWO3r17u3nSqjaTJk1y8/bt27v5vHnz3Pzss892\n8/nz57t5nz593Dzp9kmqB0gracWZ0aNHu3nS6hhXX321mz/66KOp6pk1a5abb9y40c2vvPJKNz/g\ngANS7ReQpDlz5rj5s88+m2o7zZo1c/Ok14D9+/d386QV3tJK6p+PPvrIze+7775M9gtIUvfu3d18\n5MiR1VxJzTRkyJC8S6hxCjli4n5J3nomw0MIneN/DCUAAAAAAEBqFQ4mQgjTJa2uhloAAAAAAEA9\nU5VzTFxqZm+Z2Sgz2zXpQmbW18xKzay0rKws6WIAUqCvgGzRU0D26Csge/QV6qrKDibukNROUmdJ\nSyXdknTBEMLIEEKXEEKXkpKSSu4OQHn0FZAtegrIHn0FZI++Ql1VqcFECGF5COGrEMImSXdLOizb\nsgAAAAAAQH1Q4aocHjPbI4SwNP60p6R3sisJlRFCSJUDeWrevHmqPMnMmTNT5SeeeKKbH3zwwan2\nm3T5pDO7H3rooW5eWlrq5rfffrub33HHHQVUB1SsQYMGbn7mmWe6+ezZs9086Sz+CxYscPM1a9YU\nUN3X+vXr5+Y33XSTmyddL2BbklZC+uUvf+nmSSszDRgwwM07depUucKq6IMPPnBzVt9AdfjNb37j\n5i+++KKb/+Mf/8hkv23btnXz448/3s0//PBDN09asS2tq666ys1ZReqbClku9GFJx0hqbmYfSLpO\n0jFm1llSkLRIkv/KAQAAAAAAYBsqHEyEELw/n9xbhFoAAAAAAEA9U5VVOQAAAAAAAKqEwQQAAAAA\nAMgNgwkAAAAAAJCbSq3KgZrHzPIuAah2EyZMcPOkfujZs2cxy0mUtN+k1UPat29fzHKAREmrWgwd\nOjRVvmrVKjc//PDD3XzJkiVu3rlzZzdn9Q1Uh6RVOWqaMWPGuPnNN9+cyfYPOuggN991110z2T7q\nplatWrn566+/7uYbNmxw81GjRrl5kyZN3Lx3795uvt12/t/jv/e977l5Wm3atHHzyy+/3M15Hvsm\njpgAAAAAAAC5YTABAAAAAAByw2ACAAAAAADkhsEEAAAAAADIDYMJAAAAAACQG1blqCNCCKny6dOn\nu/nBBx+cWU1Asd14441unrQqR/PmzYtZTqK5c+e6eVJ/du3atZjlAEW3adMmN9+4caObH3HEEW7e\nr1+/zGoCarvx48e7edJz4bx581JtP2n1jRdeeMHNd9lll1TbB6Tk1TSS8qxWx3n44Yfd/O233061\nne23397NBw0a5OYtW7ZMtf36jCMmAAAAAABAbhhMAAAAAACA3DCYAAAAAAAAuWEwAQAAAAAAcsNg\nAgAAAAAA5IZVOeqIpFUIksyfP79IlQDVJ+lxn5T36tWrmOUkSjozetq+BWqLhQsXuvmiRYvc/Oc/\n/3kRqwFqpgULFrj5fffd5+a33HKLm2/YsMHNGzdu7Oannnqqm995551uzuobqAtuuOGGTLbTrFkz\nN2cVqarjiAkAAAAAAJAbBhMAAAAAACA3DCYAAAAAAEBuGEwAAAAAAIDcMJgAAAAAAAC5qXBVDjPb\nS9JoSbtLCpJGhhBuN7PdJI2T1FbSIkmnhxDWFK9UbEsIIVU+bdq0YpYDVIukx3eSu+66y82zOpPy\nzJkzU+Unnniimx988MGZ1APkZdKkSXmXgHrswQcfdPM///nPbj5u3Dg3b9u2bar9vv32225+wQUX\nuPmyZcvcfMmSJan226lTJze//PLL3fy8885LtX2gNnnsscfcfO7cuZls/1e/+lUm28E3FXLExEZJ\nV4QQOkr6vqRLzKyjpKslTQ0h7Ctpavw5AAAAAABAwSocTIQQloYQZsUfr5M0V1IrST0kPRBf7AFJ\npxWrSAAAAAAAUDelOseEmbWVdJCkVyTtHkJYGn9pmaK3enjf09fMSs2stKysrAqlAtiMvgKyRU8B\n2aOvgOzRV6irCh5MmNnOkh6XNDCE8HH5r4Xojd7um71DCCNDCF1CCF1KSkqqVCyACH0FZIueArJH\nXwHZo69QVxU0mDCzRoqGEmNDCE/E8XIz2yP++h6SVhSnRAAAAAAAUFcVsiqHSbpX0twQwq3lvjRR\nUh9Jw+L/nypKhShIdDcVbrvtWCkWtV/S4z4pv+eee1JdPsm8efPcfPLkyam2P3jw4FT7BWqLhQsX\nprr8WWedVaRKUB8tXbrUzV999VU3P/fcc928SZMmqfY7e/ZsN0+7ykbTpk3d/Nhjj3XzpOe25s2b\np9ovUBf85S9/Ker2k1bBQdVVOJiQdKSk3pLeNrM34mywooHEo2Z2vqTFkk4vTokAAAAAAKCuqnAw\nEUJ4SVLSnxOPy7YcAAAAAABQn3A8PwAAAAAAyA2DCQAAAAAAkBsGEwAAAAAAIDeFnPwStUAIIVU+\nevToYpYDVIs777zTzYcOHermpaWlbj5z5kw3T+qfpFU2fvazn7n5XXfd5eZdu3Z1c6C2S1pVIMkj\njzzi5qxcg8rYcccd3XznnXd282nTphWznMTVMYYNG+bm++67r5t369Yts5qAuuq9994r6vZPP91f\n7+H1119383bt2hWznDqFIyYAAAAAAEBuGEwAAAAAAIDcMJgAAAAAAAC5YTABAAAAAAByw2ACAAAA\nAADkhlU5apkOHTq4ec+ePd18woQJxSwHyFXfvn3dPOnM5ZMnT3bzJ5980s2//e1vu/k111zj5q1b\nt3bzpDOyA3XVpZde6uZjx4518/Hjx7v5z3/+czdv2bJl5QpDvTBgwAA3P+aYY9z8uOOOc/OysjI3\n33XXXd38uuuuc/PLLrvMzQHUPuvWrXPzpJXfWJWjcBwxAQAAAAAAcsNgAgAAAAAA5IbBBAAAAAAA\nyA2DCQAAAAAAkBsGEwAAAAAAIDesylHLNGnSxM27d+/u5jNmzHDzOXPmuPnBBx9cucKAGqR9+/ap\n8oEDBxazHKDeSeq1a6+91s2ffvppN//oo4/cnFU5UBmdOnVy8xUrVlRzJQCK5YILLnDz1157zc03\nbNiQavs77LCDm/O8VHUcMQEAAAAAAHLDYAIAAAAAAOSGwQQAAAAAAMgNgwkAAAAAAJAbBhMAAAAA\nACA3Fa7KYWZ7SRotaXdJQdLIEMLtZna9pAsllcUXHRxCeKZYhWLbOnbs6OYrV65081WrVhWzHAAA\nvuGKK65IlQMAkMa5557r5m+99ZabDx8+PNX2L7nkEjc/+uijU20H31TIcqEbJV0RQphlZt+SNNPM\nnou/NjyE8F/FKw8AAAAAANRlFQ4mQghLJS2NP15nZnMltSp2YQAAAAAAoO5LdY4JM2sr6SBJr8TR\npWb2lpmNMrNdE76nr5mVmllpWVmZdxEAKdFXQLboKSB79BWQPfoKdVXBgwkz21nS45IGhhA+lnSH\npHaSOis6ouIW7/tCCCNDCF1CCF1KSkoyKBkAfQVki54CskdfAdmjr1BXFTSYMLNGioYSY0MIT0hS\nCGF5COGrEMImSXdLOqx4ZQIAAAAAgLqokFU5TNK9kuaGEG4tl+8Rn39CknpKeqc4JaIQXbt2dfNN\nmzZVcyUAAAAAUHPceuutqXJUv0JW5ThSUm9Jb5vZG3E2WNKZZtZZ0RKiiyT1K0qFAAAAAACgzipk\nVY6XJJnzpWeyLwcAAAAAANQnqVblAAAAAAAAyBKDCQAAAAAAkBsGEwAAAAAAIDcMJgAAAAAAQG4Y\nTAAAAAAAgNwwmAAAAAAAALlhMAEAAAAAAHLDYAIAAAAAAOSGwQQAAAAAAMiNhRCqb2dm6yTNr7Yd\n5q+5pJV5F1GNavv1bRNCKMm7iLToqzqvtl/fWtdX9FSdV9uvb63rKYm+qgdq+/Wlr2qH2v44S6u2\nX99UfdWwmJU45ocQulTzPnNjZqVcX1QD+qoOq2/Xt4agp+qw+nZ9axD6qg6rb9e3BqGv6rD6dn15\nKwcAAAAAAMgNgwkAAAAAAJCb6h5MjKzm/eWN64vqUN9ud64viq2+3eZcX1SH+na7c31RHerb7c71\nrcOq9eSXAAAAAAAA5fFWDgAAAAAAkBsGEwAAAAAAIDcMJgAAAAAAQG4YTAAAAAAAgNwwmAAAAAAA\nALlhMAEAAAAAAHLDYAIAAAAAAOSGwQQAAAAAAMgNgwkAAAAAAJAbBhMAAAAAACA3DCYAAAAAAEBu\nGEwAAAAAAIDcMJgAAAAAAAC5YTABAAAAAAByw2ACAAAAAADkhsEEAAAAAADIDYMJAAAAAACQGwYT\nAAAAAAAgNwwmAAAAAABAbhhMAAAAAACA3DCYAAAAAAAAuWEwAQAAAAAAclOvBxNmtsjMjs9x/x+Y\n2TF57b9YzOwCM3sx/riBma03s9aV2E4fM5uUeYEoKvqqOOir+o2+Kg76qn6jr4qDvqq/6KniMLPf\nm9n98cf/ZmbrK7mdIWZ2Z6bFZaiogwkzO8PMXjGzT8xsRfxxfzOzYu63qsxsUvxDdL2ZfWlmG8p9\nXqk708zGmNn1GdZoZvYbM1tiZh+b2UNmtnOB37uPmYVy1+n/zOzKrGorL4TwVQhh5xDCkkJq2up7\nHzKMXywAACAASURBVAghnFyMurZRx+/i2+aY6txvGvTVFtvMtK/ibbYws4fN7J9mtsbMRhf4ffSV\ns+9yt8d6Mxtc7P1WFn21xTazfr461cz+ZmZrzWypmd3F81XlmVl3M5tvZp+a2V8r8wtfdaGvttgm\nfVVATVt9b3X21ZlmNs/M1pnZO2b24+rYb1r01BbbzLqnjjezTVu9bvlZJb53XfxY6pNVbeWFEBaG\nECrs9bimRVt97w0hhIuKUZez73fin08rzexxM9ujou8r2mDCzK6QdLukP0pqKWl3SRdJOlLS9gnf\n06BY9aQRQjg5/iG6s6Sxkm7e/Ll3Z5pZw+qvUj+XdIakwyW1ktRU0e1dsHLXsbek35kz4czpuuXC\nzL4r6TRJK/KuJQl9VS2ekvS+pL0ktZA0PM0301dbKncf7xxCuCnvejz0VdF9S9JvJe0h6d8l7S1p\nWJoN0FcRM9td0mOSBkn6tqQ3JD2Ua1EJ6Kuio68yEg/3HpD0C0WvpwdLGmdm3861sK3QU9ViyVav\nW8am/V5Fj6FrJN1rZvttfaH60FOS3pF0QgihmaLfUxdJGlHhd4UQMv8naRdJn0j6SQWXu1/SHZKe\niS9/fPy9oyWVSVos6VpJ28WXv17SmHLf31ZSkNQw/vxFSTdI+n+S1kl6VlLzcpfvHW9zlaIHzCJJ\nxxdQ4++3yo6Pv3ewpGWS7pN0gaQXy12mYVxbW0n9JX0paYOk9ZImxJf5QNIvJb0t6Z+SHpa0Q4G3\n8ZOSLi/3eTdJn0pqXMD37hPd9Vtkr0saWK7u/pLelfRu/PWOkp6XtFrSvPL3raQSSU9L+ljS3yXd\nuPm2KH87xJ83UfSL3pL4Ok+XtIOkj+LLrY//HercpkdJKo2/71VJ3yv3tZcUPUH/Lb7vJ0vaLeXj\n9jlJ3eP75Zhi9AZ9VeP76hRJ722+bVLeP/RVBbdHTfwn+mqLx5OK0FdOnadLep2+qlRf9Zc0vdzn\nTSV9IWmfvHuJvqKvVHv76khJH22VrZF0aN69RE9V62vA4yUtquT9843vjR9DpynuN0nnxY/7v5Z7\n3P1d0lpFQ+Zu5b733yTNiG/zKfF9er/Xv4qG1PdLWhrv8/H4Pv9M0iZ93VMtJP1+83bi7+0paXZc\nw18l7Vfua5n8fJLUWNEw7a2KLlusIyYOV/RD5qkCLnuWoh9g31L0Q+W/Fd2Y/ybpaEnnKLojC3VW\nfPkWiqaHv5IkM+uo6E7tLek7iu7EPVNsd2t7StpZUmtFzZEohPA/ksZJuilE07ee5b58uqQTFF3f\nQ+L6Nr8nb62ZfX8bm7atPt5RUrs0V8IiXSV1UPSktNmpip4UOsWHBj6n6IdaC0k/kzSy3BTwDkWN\n01JSX0VHcyQZLukASd+TtJuiH0CbFA1WFL6eUL62VZ3NJf2vpFsU3Xf/LekZM9u13MXOktRH0QR5\nJ0XNtPn7Z5vZ6du4Hc6U9HEI4dlt1J43+qqcIvXV9yXNlzTGzFaZ2atmdlTaK0FfbbGPD8zsfTMb\nVdP++hSjr8op4vNVed0UvRBKhb6SFP1l/M3Nn4QQPpb0f3Fek9BX5dBXW6iJffWKpPfM7Ifx7f6T\n+Pq8s43rUd3oqXKK2FPfMbPlZrbQzG4xsyZpr4SZbWdmP42vy9vlvtRNUntJPzSzvSRNlHSdoj64\nWtIT5V4njVM0tGguaejm65DgIUX3S0dF99HtIYR/SvqxtjwCZIsjws2sg6QHJQ1QNFx8XtJEM2tU\n7mKVvi3NbG8zW6voD+eXSbp5G9dBUvHeytFc0soQwsZyxW1+H9xnZtat3GWfCiH8vxDCJkWTrzMk\nDQohrAshLFL0A2hbd8bW7gsh/COE8JmkRyV1jvOfSno6hDA9hPCFpCGKfhBW1kZJ14cQNsT7qqzb\nQgjLQgirFE2bO0v/ek9esxDC3xO+b7KkvmbWxsyaSboqzgtuoPjBslrSSElXhBCmlfvyTSGENfF1\n6yHpHyGE0SGEjSGEmYqO2Php/OA9TdKQEMKnIYS3FD3Ivf01kHSupF+EEJbG1/GlEMKXBZT7Y0mz\nQwgPxzU8KGmhpB+Wu8y9IYQFIYRPJY3X1/e9Qgj/HkJ4NKGupoqmwZcXUEee6KvCVbav9pR0sqLp\ndEtFh0xONLPdCt0xffUvKyR1kdRG0mGSdlX0oramoa8KV9m++hczO1nRi9zr0uyYvvqXnRX95aq8\nfyr6BaQmoa8KR1/l3Ffx43S0osfLF/HHfat4v2aNnipcZXtqtqQDFb096gRFf6z6Y4r9to57aqWi\no0d+FkJ4r9zXr4t75DNFw6GJIYQpIYRNIYTJiobOJ5nZv8V1XBdC+CKE8KKiI2C+IR5wHCfp4rhf\nvwwhTC+w3jPiGv4a9+AwRQOs75W7TKV/PoUQ/i9Eb+UokfQbRX/426ZivcdllaTmZtZwcwOFEI6Q\nor+eacuByPvlPm4uqZGiQ4I2W6zovSmFWlbu408VPYlL0STvX/sKIXxiZqtSbHdry0MIG6rw/Ztt\nXW+hvwDdreiXqOmKbs/hig5D/6DQHccPliTl75c2ko6Mm22zhooOG9pdUoOtLr9Y0S8iW9td0UTv\nPedrFfmOtnxcbN5P+cdG0n1fkRskjQoVnJipBqCvClfZvvpM0WGrD8SfjzWzaxX9peJ/C9kAfRUJ\n0V9yZ8afLjWzAZKWmFmT+EVjTUFfFa6yfSVJMrMjFL3g77XVi7UK0Vf/sl7R2zfKa6ror7s1CX1V\nOPqqMEXrKzM7SdJNkroqOqT+UElPmdkJIYS3t/nN1YeeKlyleiqEsFTR2yGk6AiaXyt6W8QlBe53\nSQih7Ta+vnVPnWlm5Y/0aKToD8/fkbRqq9dKixX9gr+1vRQNrLYeWBdii54KIWyKH0vb6qlUP5/i\n7a4yszGSXjOzVvHAzFWsIyZeVjRx7FHAZUO5j1cqmuy1KZe1lvRh/PEn2vKIgJYpalqq6M6TJMWH\n5lTlsOKw1ecV1bb15asknlRdG0JoE0LYS9H7/d7Xlg+gKu2i3MfvS5oaT8Y2/9s5hHCppOWKpqN7\nlbt80hnClyt6L5j3dpOKbp+PtOXjYvN+PnQum9Zxki43s2VmtkzRpPQJM/tVBtvOEn1V5L6S9Jaz\nzSz3UZ/6KqmWmnbmcPqq+H0lM+ui6C+sfeK//mSpPvXV5r/oSZLM7FuKTnqY+hD+IqOv6CtPTe2r\nzorOZTAr/uv1K4rOZXFcBtvOCj1VDT3lbD+z1ywhhK176r6temqnEMIfFd2u3zazHctdPqmn3lc0\nsNp6YC2l7Ckz207RH72L8RqwoaL7b5vDwqIMJkIIaxWdgOZ/zOynZvat+P02nRW95yvp+75SdIjQ\njfH3tFH0/rAx8UXekNTNzFqb2S6KzkpdqMck/cjMjjKz7SX9Ttle/zclHWBmneIH0taH0y1X9P6c\nTJhZc4vWsTUz21/Sfyk6/CnEX/+9mT2f0e4mSvp3MzvLzBrF/w4zs/3iQ3+elPRbM9sxrsU9PCy+\nf++XdJuZtYzfn3RkfBjgCkkhPnzJ83Rcw3+aWUMzO0vRyV8K+it2BY6W1EnRE1NnRffVBZJq1Dq/\n9FXx+0rRZHx3M/tZ/Pj8T0Xv13tZoq/SMLPvm9l348doiaK3xUwNIXxS1W1nib6qluerAxUdhto/\nhPCNw1Hpq1Qel9TZzE4zs8aK7rvSEMK7GWw7M/QVfeVtpAb31WuSjjazA6R/DXyOVPTHihqBnqqW\nnjrWordGbF6pZajKndPDouVJ78lodw9K6mlmJ8R90Dje/3fiI5/eknS9mW1v0dt0fuhtJITwvqJz\nQ4wws2Zxb25+W89yRUOLpLf6PSrpVDM7Ju7BKxUdffdKVa+cmf3EzPa1SAtFbx96LT6aNlHRlgsN\nIdys6IF/laIbZrmkuyT9WtEZc5MMUDQhW6johC0PSRoVb/M5RScDeUvRIcJPp6hntqJDcR7S12ct\nLfhtDwVsf46iw8BeVPQemq3f33OPpAPNbI2ZPVbR9uIH6XozOzzhIiWKDvf5RNHtcFcIYVS5r++l\n6Ay6VRYfHnSipLMV3XbLFDXrDvFFLlb0/vHlku5VdCbdJJdLmqvo/lut6DazEMK6eJuvWPR+uS5b\n1VCm6ERMv1Z0ONvlkn4UQlhTyHWwaM33/0y4fqvi908tCyEsUzT5Xx1CWF/ItqsTfVXcvgohrFT0\n14hBit63/StJp4YQVscXoa/K2VZfKXrB+KyiJ7k3FR2CXtB64NWNvir689WvFJ813L5eG/7Ncl+n\nr8qp4PlquaKTkd2s6HFxsKJzC9Q49BV9laAm9tVURasVTDCzdYoeY78NIfy1kG1XF3qq6D3VRdLf\nzexTRbfTLG15/rkse2qRohUxhihaLWWJpCv09e/mZygajq1WdL4K97wtsbPj//+h6DExIN7HO4qG\n2YvinmqxVQ2zFZ0s9o64hpMUveat8JwvBdyWeyl6Dbhe0WvADYrOSbLt7W55VAnqCjN7S9LRhf7A\nBlAx+grIHn0FZI++ArJj0RFqsyQdEMqdgBTZYjABAAAAAAByU7S3cgAAAAAAAFSEwQQAAAAAAMgN\ngwkAAAAAAJCbhlX5ZjM7SdEScA0k3RNCGLatyzdv3jy0bdu2KrsEimbmzJkrQwgledeRFn2Fmqw2\n9hU9hZqsNvaURF+hZqOvgOyl7atKDybMrIGkEZJOULQ0zGtmNjFe2sXVtm1blZaWVnaXQFGZ2eK8\na6gM+go1WW3sK3oKNVlt7CmJvkLNRl8B2UvbV1V5K8dhkt4NISwMIWyQ9IikHlXYHgAAAAAAqGeq\nMphoJen9cp9/EGdbMLO+ZlZqZqVlZWVV2B2AzegrIFv0FJA9+grIHn2FuqroJ78MIYwMIXQJIXQp\nKal1b90CaiT6CsgWPQVkj74Cskdfoa6qymDiQ0l7lft8zzgDAAAAAAAoSFUGE69J2tfM9jaz7SWd\nIWliNmUBAAAAAID6oNKrcoQQNprZpZKmKFoudFQIYXZmlQEAAAAAgDqv0oMJSQohPCPpmYxqAQAA\nAAAA9UzRT34JAAAAAACQhMEEAAAAAADIDYMJAAAAAACQGwYTAAAAAAAgNwwmAAAAAABAbhhMAAAA\nAACA3DCYAAAAAAAAuWEwAQAAAAAAcsNgAgAAAAAA5IbBBAAAAAAAyA2DCQAAAAAAkBsGEwAAAAAA\nIDcMJgAAAAAAQG4YTAAAAAAAgNwwmAAAAAAAALlpmHcBtdXy5cvdfMGCBW6+du1aN7/55pvd/Kab\nbkpVz1FHHZXq8kBN9OCDD7r54sWL3fw3v/lNMctRCMHNR4wY4eb9+/cvZjlA0X355Zdu/tBDD7n5\n1KlT3Typl/OSVM8ZZ5zh5g0b8vII+fn888/d/Prrr3fz8ePHu/kuu+zi5n/605/cnNeSAPLEERMA\nAAAAACA3DCYAAAAAAEBuGEwAAAAAAIDcMJgAAAAAAAC5YTABAAAAAAByU6XTTpvZIknrJH0laWMI\noUsWRdUkq1atcvMBAwa4+WOPPZbJfrt165bq8qNHj3bzs88+O4tygEy9//77bn7VVVe5+YoVK9zc\nzFLtd99993XzpNV0kgwaNMjN9957bzc/+eSTU20fyMqmTZvcPGmVihtvvNHN0/ZITdO7d283//vf\n/+7mQ4cOdfOdd97ZzdP+LAK25Q9/+EOq/Lvf/a6bz549282vvPJKN3/55ZcLqA6oGWbOnOnmEyZM\ncPM5c+a4+ZNPPunmSSuzdejQwc1Xrlzp5r169XLzs846y83T/g5Yl2SxHtaxIQT/ngAAAAAAANgG\n3soBAAAAAAByU9XBRJD0rJnNNLO+3gXMrK+ZlZpZaVlZWRV3B0Cir4Cs0VNA9ugrIHv0Feqqqg4m\njgohHCzpZEmXmNk33hQTQhgZQugSQuhSUlJSxd0BkOgrIGv0FJA9+grIHn2FuqpKg4kQwofx/ysk\nTZB0WBZFAQAAAACA+qHSJ780s50kbRdCWBd/3F3S7zKrrIY4//zz3XzixInVXMm2/eIXv3Dzr776\nys379OlTzHIASdKnn37q5j169HDzpNU3GjRo4OZJq850797dzbt08RcOKi0tdfPp06e7+T777OPm\nHTt2dHMgL++++66bn3vuudVbSA01YsSIVPnatWvdfJdddsmsJtQf48aNc/Ok1Tcuv/xyN7/11lvd\n/KKLLnLz+++/383fe+89N2/Xrp2bA1l64okn3DxplaSkVTmSVklKWmUj6fJJR6O0aNHCzefNm+fm\nd999t5tPmTLFzbt27ermSSsw1iVVWZVjd0kT4juzoaSHQgiTM6kKAAAAAADUC5UeTIQQFko6MMNa\nAAAAAABAPcNyoQAAAAAAIDcMJgAAAAAAQG4YTAAAAAAAgNxU5eSXtdKqVavcPGn1jf/93/8tZjmZ\n+fzzz9185cqV1VwJ8LUvv/zSzd98881U22nVqpWbjxo1KnVNnqRVNs4444xMtg8U28aNG9086Szn\nqJzf/va3bp60KgIgSR999JGbJ62QlrSy1NVXX51qvwce6J8K7osvvnDzWbNmuTmrciBLvXv3dvMx\nY8a4edpVNpI0adLEzTt06ODmSSvI/eQnP3HzGTNmuHmvXr3cfM6cOW5+xRVXuPnIkSPdvG/fvm5e\nG3HEBAAAAAAAyA2DCQAAAAAAkBsGEwAAAAAAIDcMJgAAAAAAQG4YTAAAAAAAgNzU2VU5li9f7uYD\nBgxw84kTJxaznKIbMmSImyed2bXYklYJGTt2rJsfdthhbt6pU6fMagKAuurOO+9080GDBlVzJZGW\nLVu6+cUXX+zmkyZNcvOkVQI2bNhQucKqaPjw4W7OqhyQklfHOffcc928UaNGbv7nP//ZzVu0aJGq\nnuOOOy7V5YHqMG/ePDdPWn0jKe/WrZubJ62ycdlll7l5+/bt3TytpP0mSao/6fmwPuCICQAAAAAA\nkBsGEwAAAAAAIDcMJgAAAAAAQG4YTAAAAAAAgNwwmAAAAAAAALmps6tyLFiwwM0fe+yxaq4kctNN\nN7n57rvvnsn2zzvvvEy2k5XBgwe7+W233ebmSatyjBkzxs332WefyhWGapV0JuVmzZq5+dq1a4tZ\nDlDrJfXI7bffXtT9Nm7c2M2Tftb37dvXzZOe837zm9+4+V/+8hc3//Wvf+3mc+fOdXOgOqxYscLN\nn3vuOTd/8skn3bx169aZ1PPFF19ksh0gS6NHj3bzsrIyN+/YsaObN2/ePNV+J0+enCpfuXKlmyc9\n7zVp0iRVPUnSXq+6hCMmAAAAAABAbhhMAAAAAACA3DCYAAAAAAAAuWEwAQAAAAAAcsNgAgAAAAAA\n5KbCVTnMbJSkH0laEULYP852kzROUltJiySdHkJYU7wy89OoUSM3T1pVYNCgQW7ev39/N99+++0r\nV1gNN2nSpFSXf/XVV9086Qy9rMpROzRt2tTNr7zySje/5pprilkOUOstXrzYzd99992i7rdz585u\nPmTIkKLu98c//rGbr1njv+To06dPMcsBtumRRx5Jdfnu3bsXqZLIuHHj3Dzpte1ee+1VzHIASVKH\nDh1S5Wn17t3bzceOHevmSSvIJa2OkbTqVFar6dRnhRwxcb+kk7bKrpY0NYSwr6Sp8ecAAAAAAACp\nVDiYCCFMl7R6q7iHpAfijx+QdFrGdQEAAAAAgHqgsueY2D2EsDT+eJmk3ZMuaGZ9zazUzEqTDssH\nkA59BWSLngKyR18B2aOvUFdV+eSXIYQgKWzj6yNDCF1CCF1KSkqqujsAoq+ArNFTQPboKyB79BXq\nqsoOJpab2R6SFP+/IruSAAAAAABAfVHhqhwJJkrqI2lY/P9TmVVUw7Rr187N58yZU82V1Eyvv/66\nm69fv76aKwEqtnbtWjdPOpP/tGnT3Hzfffd18/Hjx7t527ZtKy4OKMBdd92VdwlArfXUU/7L1YUL\nF7r5Oeec4+affvqpm998881ufvHFF7t548aN3bzYklaE+/73v1/NlQAVmzt3rpv36tXLzefPn+/m\n0UH+39SzZ083/9nPfubmrL5RPBUeMWFmD0t6WdJ+ZvaBmZ2vaCBxgpktkHR8/DkAAAAAAEAqFR4x\nEUI4M+FLx2VcCwAAAAAAqGeqfPJLAAAAAACAymIwAQAAAAAAcsNgAgAAAAAA5Kayq3LUeP/zP/+T\ndwl1yquvvurmF154oZt/+OGHxSwHtcRnn33m5hMnTky1nY0bN7p5WVmZmyet692oUSM3b9jQ/1H4\n8ccfu/msWbPc/PTTT3fzpP4B0tpzzz3r1X6BLCWdrf+6665z80ceecTNr732WjdPWpHssssuc3Mz\nc/OsPPnkk27eqVOnou4XqIyk1TcOO+wwN//kk0/cPKmvrrnmGjcfNGiQmzdp0sTNUTwcMQEAAAAA\nAHLDYAIAAAAAAOSGwQQAAAAAAMgNgwkAAAAAAJAbBhMAAAAAACA3dXZVjocfftjNi30G5Lrq7bff\nTpUDkrTjjju6+amnnurmr7zyipt/9NFHbn7fffe5+VVXXeXmO+20k5sPHDjQzXfYYQc3HzdunJu/\n8847bv7UU0+5eY8ePdwcSHLeeee5edLZxrPy+eefu/m0adNSbeeggw5y86ZNm6auKQ9nn3123iWg\nCpKeGz799FM3/+1vf+vmSc9hzZs3d/P99tuvgOoqb+nSpanybt26FbMcoFImT57s5kmrb4QQ3Lx9\n+/ZufsMNN1SuMFQbjpgAAAAAAAC5YTABAAAAAAByw2ACAAAAAADkhsEEAAAAAADIDYMJAAAAAACQ\nmzq7Ksf+++/v5klnzU+SdMbX2m7OnDlu/sYbb7j5BRdcUMxyEtXV27++u/rqq938zjvvdPMlS5ak\n2s5FF13k5kln/u/atWuqfPbs2W6etEpNz5493Xz06NFuzpn/kfSz+OKLL67mSiJPP/10qjxJ586d\n3TypN/v16+fmST1YbNdff30u+0VxJT2X3HHHHW6+YsUKN2/ZsmVmNaUxdepUN1+9enU1VwJUXseO\nHd087YqK8+fPd/OTTz7ZzZNeo/Xt2zfVflF1HDEBAAAAAAByw2ACAAAAAADkhsEEAAAAAADIDYMJ\nAAAAAACQGwYTAAAAAAAgNxWuymFmoyT9SNKKEML+cXa9pAsllcUXGxxCeKZYRVZG0pmUu3Xrlmo7\na9ascfNJkya5edIZX2uawYMHu/nEiRPdPO0ZcbOS136Rj6T7O+3j4KabbnLzYcOGpa7J84c//MHN\nb7zxRjf/29/+5ubjx493c1blqD/efPNNN096Llm2bFkxyym6pNVGkkyfPr1IlWxb79693Xzvvfeu\n5kpQHRo3buzmAwcOdPOk11Ddu3fPrKY0nn/++VSXT1odB8jTiSee6OZJr5VWrlzp5hMmTHDzmTNn\nuvmUKVPcfPjw4W4+ZswYNz/kkEPcHIUr5IiJ+yWd5OTDQwid4381aigBAAAAAABqhwoHEyGE6ZJY\nCBkAAAAAAGSuKueYuNTM3jKzUWa2a9KFzKyvmZWaWWlZWVnSxQCkQF8B2aKngOzRV0D26CvUVZUd\nTNwhqZ2kzpKWSrol6YIhhJEhhC4hhC4lJSWV3B2A8ugrIFv0FJA9+grIHn2FuqpSg4kQwvIQwlch\nhE2S7pZ0WLZlAQAAAACA+qDCVTk8ZrZHCGFp/GlPSe9kV1LNsmLFCjfv37+/m999991ufvzxx2dW\nk2fOnDlunnTm6FdffbWY5aR27rnnuvl+++1XvYUgV+eff76bJ612sWHDBjdfvHixm2/cuNHNGzZM\n96PwpJO88wFLhx9+uJvvtttubp60QkFSzpnU656HHnrIzWv76hu13fr16/MuATVAp06d8i6hIEnP\nbbvssoub/+AHPyhmOUCmevXqleryffv2dfMlS5a4edLqHkkrpB12mP/3+Msuu8zNk34Xa968uZvX\nZ4UsF/qwpGMkNTezDyRdJ+kYM+ssKUhaJKlfEWsEAAAAAAB1VIWDiRDCmU58bxFqAQAAAAAA9UxV\nVuUAAAAAAACoEgYTAAAAAAAgNwwmAAAAAABAbiq1Kkdt0KRJEzdv0aKFmyetvpEk6az/SWeO3WGH\nHVJtP62k1QnWrVtX1P1mJWkd5h133LGaK0Gerr32WjdPOrP4wIED3fzRRx9186RVXq6//vqKiyuC\nDz74wM0feOABN2dVjtprzJgxbj5q1KhqrgSFmDBhgpu/9dZbbk5vIkufffaZm0+dOtXNx44dm2r7\nt956q5snrZCWtAoBUJu0bt06VZ604uETTzzh5hdddJGb77TTTm7+i1/8ws2TfieqDzhiAgAAAAAA\n5IbBBAAAAAAAyA2DCQAAAAAAkBsGEwAAAAAAIDcMJgAAAAAAQG7q7KocBx98sJvfd999bt6/f383\nT1p9I8n69etT5VkJIbi5mRV1v1n54x//6OannXaamx9++OHFLAc1TI8ePdw8aVWOJA8++KCbn3fe\neW7epk2bVNvPyiOPPOLml156qZu3a9eumOUgA7179867BGQg6WzsrMpRNzVt2tTNGzVq5Oa77rpr\nqu1/8sknbp70Guftt99Otf0kd9xxh5snrRKUtGpBUj/sv//+lSsMqAWSVmBMes34wx/+0M0nT57s\n5kmr5nTt2rWA6mo3jpgAAAAAAAC5YTABAAAAAAByw2ACAAAAAADkhsEEAAAAAADIDYMJAAAAAACQ\nmzq7KkeSk08+2c0PPPBAN0+7Kkdd1a1bNzdPWg1kxowZxSwH9UxJSYmbX3jhhW6edGbxRYsWuflD\nDz3k5oMGDaq4uHKSVsFp1qyZm69du9bNV6xY4eaPP/64m1911VUFVAegqg466KC8S0A1SnrtM2vW\nLDdPu0LSAw884OZJrz2TzvqfdPmk1Te+/e1vu3nSc8zEiRPd/JRTTnHzKVOmuHmHDh3cHKgLDjnk\nEDd/4YUX3Pzoo4928379+rn5tGnT3DzpNXJtxBETAAAAAAAgNwwmAAAAAABAbhhMAAAAAACA9Ykr\nlQAACztJREFU3DCYAAAAAAAAuWEwAQAAAAAAclPhqhxmtpek0ZJ2lxQkjQwh3G5mu0kaJ6mtpEWS\nTg8hrCleqcU1YsQIN589e7abf/zxx26+bt06N//8888rV1gV7bTTTm7+pz/9yc2PPPJIN99ll13c\nfOjQoW7+8ssvu/nGjRvdHNiWHXfc0c3vvPNONx83bpybJ/Xttdde6+ZJZxA/7bTT3Lxp06ZufuWV\nV7r5Nddc4+YAsnXeeee5eePGjd38iCOOcPOk3kf9sv/++2eynV/96lduvs8++7j5smXL3LxHjx5u\n3qdPHzdPek79j//4Dzd/+umn3fzHP/6xm59//vlunrRiW4MGDdwcqAuSXkveeuutbp70c+Gcc85x\n80mTJlWusBqokCMmNkq6IoTQUdL3JV1iZh0lXS1paghhX0lT488BAAAAAAAKVuFgIoSwNIQwK/54\nnaS5klpJ6iFp8wLMD0jizwgAAAAAACCVVOeYMLO2kg6S9Iqk3UMIS+MvLVP0Vg/ve/qaWamZlZaV\nlVWhVACb0VdAtugpIHv0FZA9+gp1VcGDCTPbWdLjkgaGELZ4o3YIISg6/8Q3hBBGhhC6hBC6lJSU\nVKlYABH6CsgWPQVkj74Cskdfoa4qaDBhZo0UDSXGhhCeiOPlZrZH/PU9JK0oTokAAAAAAKCuKmRV\nDpN0r6S5IYTypw+dKKmPpGHx/08VpcJq0qpVKzdfsGBBqu3893//t5u/8MILbr506VI3/+STT9w8\n6UzN0UEr39SzZ083Tzqza1q33Xabm0+ZMsXN58+fn8l+gW255ZZb3PzCCy9MtZ0zzzzTzW+44QY3\n/853vuPmb731Vqr9ou559NFH3fz000+v5krytffee7t50moX/fr1c/O0fyVs1qyZm2+3Haumo+Z5\n++23U10+6bVe0uobaZ1yyiluPm3aNDc/+uij3XzIkCGp8qzqRz4WL16c6vJt2rQpUiU109lnn+3m\nY8eOdfPJkye7edLvYgMHDqxcYTmqcDAh6UhJvSW9bWZvxNlgRQOJR83sfEmLJdWvV1cAAAAAAKDK\nKhxMhBBekmQJXz4u23IAAAAAAEB9wjGMAAAAAAAgNwwmAAAAAABAbhhMAAAAAACA3BRy8kukMGDA\ngFT5u+++6+Zr1qxx80MPPbRyhQH1SMuWLd38gAMOcPOPPvrIzcvKytz817/+deUK20rTpk3d/KCD\nDnLzs846K5P9ovr99Kc/dfMnn3zSzX//+9+7eWlpaWY1pZG0clXSWcWTJK2M065du9Q1AbXdTjvt\n5OafffaZmx944IFunrQqR1aSVq858sgj3fzqq69282HDhrn5eeed5+b77rtvAdWhppowYYKbJz0O\n9tprr2KWk5mkfmvfvn2q7axcuTJVHi2U+U11acVDjpgAAAAAAAC5YTABAAAAAAByw2ACAAAAAADk\nhsEEAAAAAADIDYMJAAAAAACQG1blyNk+++yTdwlAnXPKKaekymfMmOHms2fPdvOkMyPff//9bv7q\nq6+6+YgRI9yc1TfqnqTHTI8ePdz8Rz/6kZv/85//dPPbbrvNzXfbbTc3v+SSS9w8SVL9DRvyMgKo\nrP/6r/9y80GDBrn5rbfe6uZJKzwVW4MGDdx86NChbn7SSSe5edKqP6jdBg4cmCofOXJkqu0nvXab\nN2+emyetapX0/BZCcPOZM2emunza7ae9fF3CERMAAAAAACA3DCYAAAAAAEBuGEwAAAAAAIDcMJgA\nAAAAAAC5YTABAAAAAAByY9V5hs8uXbqEpDOiAnkzs5khhC5515EWffX/27tjUDvPMg7g/4e2TnWo\nJIQSEyvSIXdqIRRBB8fqUl3EQqRTdFCw0KVk0cVNqw4SSGhoJUURWrRDl1IEdSnGIrZ6CRZRVGIa\ncWg2qX0dzhku4Zbkyjnf+933+/2W+533nMP3Puc+/+XhnO9jzg5jrmSKOTuMmUrkinmTq/Fdvnx5\n3/WdnZ191y9evLjN7WR3d3ff9VOnTu27fuTIkX3Xz549u+/6yZMn/7+NbdBBc+UbEwAAAEA3BhMA\nAABANwYTAAAAQDcGEwAAAEA3BhMAAABAN3ff7gVVdSLJj5IcS9KSXGit/aCqvpXkbJIb65eea629\nsq2NAgAAwEGdOXPmQK8/f/78lnbCB7ntYCLJe0meaq29UVUfTvLbqnp1/dz3Wmvf2d72AAAAgJHd\ndjDRWruW5Nr6+GZV7SY5vu2NAQAAAOM70DUmquqBJA8neX299PWq+n1VXaqq+z7gPV+pqitVdeXG\njRv7vQQ4ILmCzZIp2Dy5gs2TK0Z1x4OJqro3yYtJnmytvZvkfJJPJHkoq29UfHe/97XWLrTWTrfW\nTh89enQDWwbkCjZLpmDz5Ao2T64Y1R0NJqrqnqyGEi+01l5Kktba9dbaf1tr7ye5mOSR7W0TAAAA\nGNFtBxNVVUmeTbLbWntmz/r9e172hSRvbX57AAAAwMju5K4cn0ry5SRvVtXv1mvnkjxeVQ9ldQvR\nvyT56lZ2CAAAAAzrTu7K8esktc9Tr2x+OwAAAMCSHOiuHAAAAACbZDABAAAAdGMwAQAAAHRjMAEA\nAAB0YzABAAAAdGMwAQAAAHRjMAEAAAB0YzABAAAAdGMwAQAAAHRTrbXpTlZ1M8nVyU7Y35Ek/+q9\niQkd9no/1lo72nsTByVXwzvs9R66XMnU8A57vYcuU4lcLcBhr1euDofD3mcHddjrPVCu7t7mTvZx\ntbV2euJzdlNVV9TLBORqYEurdyZkamBLq3dG5GpgS6t3RuRqYEur1085AAAAgG4MJgAAAIBuph5M\nXJj4fL2plyks7XNXL9u2tM9cvUxhaZ+7epnC0j539Q5s0otfAgAAAOzlpxwAAABANwYTAAAAQDeT\nDCaq6tGqulpVb1fV01Occ2pVdamq3qmqt/asfaSqXq2qP63/3tdzj5tSVSeq6hdV9ceq+kNVfWO9\nPmS9cyVXY/WZXM3D6LlaUqYSuZoLuRqrx+RqHuRqnB6TqZWtDyaq6q4kP0zy2SQ7SR6vqp1tn7eD\n55I8esva00lea609mOS19eMRvJfkqdbaTpJPJvna+n86ar2zI1dD9plcdbaQXD2X5WQqkavu5GrI\nHpOrzuRquB6TqUzzjYlHkrzdWvtza+0/SX6S5LEJzjup1tovk/z7luXHkjy/Pn4+yecn3dSWtNau\ntdbeWB/fTLKb5HgGrXem5GplmD6Tq1kYPldLylQiVzMhV4P1mFzNglwN1GMytTLFYOJ4kr/tefz3\n9doSHGutXVsf/zPJsZ6b2YaqeiDJw0lezwLqnRG5Whmyz+Sqm6XmahE9JlfdyNXAPSZX3cjVoD22\n5Ey5+OVE2uq+rEPdm7Wq7k3yYpInW2vv7n1uxHqZnxH7TK7oadQekyt6GrXH5IqeRuyxpWdqisHE\nP5Kc2PP4o+u1JbheVfcnyfrvO533szFVdU9WwXmhtfbSennYemdIrjJen8lVd0vN1dA9JlfdydWA\nPSZX3cnVYD0mU9MMJn6T5MGq+nhVfSjJl5K8PMF55+DlJE+sj59I8vOOe9mYqqokzybZba09s+ep\nIeudKblaGabP5GoWlpqrYXtMrmZBrgbrMbmaBbkaqMdkaqVW3wrZ8kmqPpfk+0nuSnKptfbtrZ90\nYlX14ySfSXIkyfUk30zysyQ/TXIyyV+TfLG1dutFXA6dqvp0kl8leTPJ++vlc1n9Fmq4eudKrsbq\nM7mah9FztaRMJXI1F3I1Vo/J1TzI1Tg9JlMrkwwmAAAAAPbj4pcAAABANwYTAAAAQDcGEwAAAEA3\nBhMAAABANwYTAAAAQDcGEwAAAEA3BhMAAABAN/8DGrq/mG52zEkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv9Epu7QO1xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}